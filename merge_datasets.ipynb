{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea40e3ac-9b6b-4ced-adc9-88ececd93198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d5a5054-3389-468c-b519-847466efae67",
   "metadata": {},
   "source": [
    "Define dir to data pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bef3d3f6-38ab-48a0-9f85-da098932bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "station = \"II_297_1\"\n",
    "\n",
    "era_5_evap_dir = os.path.join(data_path,\"era5_evaporation.pickle\")\n",
    "era_5_soil_lvl1_dir = os.path.join(data_path, \"era5_vol_soil_lvl_1.pickle\")\n",
    "era_5_soil_lvl2_dir = os.path.join(data_path, \"era5_vol_soil_lvl_2.pickle\")\n",
    "era_5_soil_lvl3_dir = os.path.join(data_path, \"era5_vol_soil_lvl_3.pickle\")\n",
    "era_5_soil_lvl4_dir = os.path.join(data_path, \"era5_vol_soil_lvl_4.pickle\")\n",
    "precip_dir = os.path.join(data_path, \"gpm-imerg_df.pickle\")\n",
    "grace_dir = os.path.join(data_path, \"grace_df.pickle\")\n",
    "target_dir = os.path.join(data_path, station + \".pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34618edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(column):\n",
    "    min_val = min(column.apply(lambda d: np.min(d)))\n",
    "    max_val = max(column.apply(lambda d: np.max(d)))\n",
    "    column = column.apply(lambda d: (d - min_val) / (max_val - min_val))\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b39c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess_data(data_dir, prefix):\n",
    "    pickle = pd.read_pickle(data_dir)\n",
    "    pickle[\"value\"] = pickle[\"value\"].apply(lambda x: np.nan_to_num(x=x, nan=np.nanmean(x)))\n",
    "    pickle[\"value\"] = normalize_data(pickle[\"value\"])\n",
    "    pickle = pickle.rename(columns={\"value\": prefix + \"_value\"})\n",
    "    pickle = pickle.sort_values(by=\"date\", ignore_index=True)\n",
    "    pickle = pickle.set_index(\"date\")\n",
    "    return pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccfe0451-3978-423b-8335-ab8afc34b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess_data_with_mask(data_dir, prefix):\n",
    "    pickle = pd.read_pickle(data_dir)\n",
    "    pickle[\"value\"] = pickle[\"value\"].apply(lambda x: np.nan_to_num(x=x, nan=np.nanmean(x)))\n",
    "    pickle[\"value\"] = normalize_data(pickle[\"value\"])\n",
    "    pickle[\"mask\"] = pickle[\"mask\"].apply(lambda x: x.astype(float))\n",
    "    pickle = pickle.rename(columns={\"value\": prefix + \"_value\", \"mask\": prefix + \"_mask\"})\n",
    "    pickle = pickle.sort_values(by=\"date\", ignore_index=True)\n",
    "    pickle = pickle.set_index(\"date\")\n",
    "    return pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fddd6950-4d7a-4900-b860-456d93168757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_soil_lvls(lvl1_dir, lvl2_dir, lvl3_dir, lvl4_dir):\n",
    "    return read_and_preprocess_data(lvl1_dir, \"lvl1\"), read_and_preprocess_data(lvl2_dir, \"lvl2\"), read_and_preprocess_data(lvl3_dir, \"lvl3\"), read_and_preprocess_data(lvl4_dir, \"lvl4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1056a3d2-f020-4360-b508-e78160374a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaporation_data = read_and_preprocess_data(era_5_evap_dir, \"evap\")\n",
    "lvl1, lvl2, lvl3, lvl4 = read_soil_lvls(era_5_soil_lvl1_dir, era_5_soil_lvl2_dir, era_5_soil_lvl3_dir, era_5_soil_lvl4_dir)\n",
    "precip_data = read_and_preprocess_data(precip_dir, \"precip\")\n",
    "grace_data = read_and_preprocess_data_with_mask(grace_dir,\"grace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f30c15c4-78d8-4fca-8d81-d39e2123424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_pickle(target_dir)\n",
    "target = target.rename(columns = {\"value\": \"target\"})\n",
    "target = target.sort_values(by=\"date\", ignore_index=True)\n",
    "target = target.set_index(\"date\")\n",
    "target = read_and_preprocess_data(target_dir, \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0319a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-01-01</th>\n",
       "      <td>0.363889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-02-01</th>\n",
       "      <td>0.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-03-01</th>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-01</th>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-01</th>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target_value\n",
       "date                    \n",
       "2002-01-01      0.363889\n",
       "2002-02-01      0.116667\n",
       "2002-03-01      0.075000\n",
       "2002-04-01      0.222222\n",
       "2002-05-01      0.366667"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d7f4949-143e-46f5-8cbc-1c5b71d6587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [evaporation_data, lvl1, lvl2, lvl3, lvl4, precip_data, grace_data, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fcc994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment if you only want to use grace\n",
    "\n",
    "dfs = [grace_data, target]\n",
    "#dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10a4bd0b-a522-4d20-bb5a-0303d447760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(dfs, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8113fd90-c816-4ebc-8c16-bc2f9d217534",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['target_value'].isna()\n",
    "\n",
    "# stwórz serię liczb całkowitych, które będą używane do stworzenia grup\n",
    "groups = (mask != mask.shift()).cumsum()\n",
    "\n",
    "# stwórz grupy, dla których w kolumnie nie ma wartości NaN\n",
    "valid_groups = groups[~mask]\n",
    "\n",
    "# policz długości grup\n",
    "group_lengths = valid_groups.groupby(valid_groups).size()\n",
    "\n",
    "# znajdź indeks grupy o największej długości\n",
    "longest_group_index = group_lengths.idxmax()\n",
    "\n",
    "# stwórz maskę dla wierszy należących do grupy o największej długości\n",
    "longest_group_mask = (groups == longest_group_index) & (~mask)\n",
    "\n",
    "# wybierz wiersze należące do grupy o największej długości\n",
    "longest_group = data[longest_group_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5406ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = longest_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b7e9d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['grace_value'].isna()\n",
    "\n",
    "# stwórz serię liczb całkowitych, które będą używane do stworzenia grup\n",
    "groups = (mask != mask.shift()).cumsum()\n",
    "\n",
    "# stwórz grupy, dla których w kolumnie nie ma wartości NaN\n",
    "valid_groups = groups[~mask]\n",
    "\n",
    "# policz długości grup\n",
    "group_lengths = valid_groups.groupby(valid_groups).size()\n",
    "\n",
    "# znajdź indeks grupy o największej długości\n",
    "longest_group_index = group_lengths.idxmax()\n",
    "\n",
    "# stwórz maskę dla wierszy należących do grupy o największej długości\n",
    "longest_group_mask = (groups == longest_group_index) & (~mask)\n",
    "\n",
    "# wybierz wiersze należące do grupy o największej długości\n",
    "longest_group_grace = data[longest_group_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "addb836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = longest_group_grace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ceff6312-fb41-46c8-8cec-e3eeac888ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grace_value</th>\n",
       "      <th>grace_mask</th>\n",
       "      <th>target_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [grace_value, grace_mask, target_value]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan = data.loc[data[\"grace_value\"].isna()]\n",
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4b9ea17-541a-49c4-905e-25d619e18e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_value(nans, idx):\n",
    "    l = []\n",
    "    for i in range(nans):\n",
    "        arr = np.full(shape=(8, 13), fill_value=-999999)\n",
    "        l.append(arr)\n",
    "    l = pd.Series(l, idx)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1215123f-835b-453b-9589-441eafcad24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_nans(nans, idx):\n",
    "    l = []\n",
    "    for i in range(nans):\n",
    "        arr = np.ones(shape=(8, 13), dtype=np.float32)\n",
    "        arr[0] = 0.0\n",
    "        l.append(arr)\n",
    "    l = pd.Series(l, idx)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d82f29c-159c-40c5-8099-2b418d939bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use it if you have nan values in grace\n",
    "\n",
    "#idx = data['grace_value'].loc[data['grace_value'].isna()].index \n",
    "#data.loc[data['grace_value'].isna(), \"grace_value\"] = fill_missing_value(36, idx)\n",
    "#data.loc[data['grace_mask'].isna(), \"grace_mask\"] = fill_missing_nans(36, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0178f007-7e43-42da-a4a8-659baadee64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()\n",
    "data = data.drop(columns=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0f7b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_with_zero(a):\n",
    "    where_are_NaNs = np.isnan(a)\n",
    "    a[where_are_NaNs] = 0\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81580a85-c0a6-4371-95d7-4b22858b49f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"grace_value\"] = data[\"grace_value\"].apply(lambda x: fillna_with_zero(x))\n",
    "data[\"merged\"] = data.apply(lambda row: np.hstack((row.loc[data.columns != \"target_value\"])), axis=1)\n",
    "data[\"merged\"] = data[\"merged\"].apply(lambda x: np.hstack((x))) \n",
    "columns_to_drop = [x for x in data.columns if x not in [\"target_value\", \"merged\"]]\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "#data[\"merged\"] = data[\"merged\"].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20defda0-9ba1-480c-9cc6-4645e725e1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [0.6292248749725716, 0.6292248749725716, 0.629...\n",
       "1      [0.5887092461231348, 0.5887092461231348, 0.588...\n",
       "2      [0.4934141092587748, 0.4934141092587748, 0.493...\n",
       "3      [0.43022824656518793, 0.43022824656518793, 0.4...\n",
       "4      [0.4260858280886991, 0.4260858280886991, 0.426...\n",
       "                             ...                        \n",
       "198    [0.18272711489209306, 0.18272711489209306, 0.1...\n",
       "199    [0.20195293831187738, 0.20195293831187738, 0.2...\n",
       "200    [0.24025719462417888, 0.24025719462417888, 0.2...\n",
       "201    [0.10029274231134166, 0.10029274231134166, 0.1...\n",
       "202    [0.14576012421472964, 0.14576012421472964, 0.1...\n",
       "Name: merged, Length: 203, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"merged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e797fa21-4072-40d9-ae85-4e1b6ebdb5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(\"data/ready_dataset_.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3bc2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
