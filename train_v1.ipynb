{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Izn_VW1w4oz7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izn_VW1w4oz7",
        "outputId": "81e42cd8-d2bd-45ab-9fe7-de1b65f144b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ray in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from ray) (23.1.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.12.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (23.1)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.27.1)\n",
            "Requirement already satisfied: grpcio<=1.51.3,>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.51.3)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from ray) (1.22.4)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.19.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.4)\n"
          ]
        }
      ],
      "source": [
        "pip install ray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "056e29ce-356d-4c7a-9660-959071839ccb",
      "metadata": {
        "id": "056e29ce-356d-4c7a-9660-959071839ccb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import copy\n",
        "import multiprocessing\n",
        "import os\n",
        "import ray\n",
        "from ray import tune\n",
        "from ray.air import session\n",
        "from ray.air.checkpoint import Checkpoint\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "import xgboost as xgb\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KZTbx598esKR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZTbx598esKR",
        "outputId": "be7eaea9-b8d9-48a8-e4a4-ce0af441ea5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "159f1676",
      "metadata": {
        "id": "159f1676"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, target):\n",
        "        self.data = data\n",
        "        self.target = target\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index], self.target[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5179ef6",
      "metadata": {
        "id": "a5179ef6"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, tolerance=5, min_delta=0):\n",
        "\n",
        "        self.tolerance = tolerance\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, train_loss, validation_loss):\n",
        "        if (validation_loss - train_loss) > self.min_delta:\n",
        "            self.counter +=1\n",
        "            if self.counter >= self.tolerance:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.counter = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05c995c5-1d9d-44d1-b059-c33d30369802",
      "metadata": {
        "id": "05c995c5-1d9d-44d1-b059-c33d30369802"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Inicjalizacja stanu ukrytego LSTM\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        # Przekazanie danych wejściowych przez warstwę LSTM\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "\n",
        "        # Przekazanie ostatniego kroku czasowego przez warstwę Fully Connected\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xsbl4zsbEOLf",
      "metadata": {
        "id": "Xsbl4zsbEOLf"
      },
      "outputs": [],
      "source": [
        "def train_fn(config):\n",
        "  train_loader = DataLoader(config[\"ds\"], batch_size=config[\"batch_size\"], shuffle=False)\n",
        "\n",
        "  test_dataloader = DataLoader(config[\"test_ds\"], batch_size=config[\"batch_size\"], shuffle=False)\n",
        "\n",
        "  early_stopping = EarlyStopping(tolerance=config[\"tolerance\"], min_delta=config[\"min_delta\"])\n",
        "\n",
        "  #model = ConvLSTM(8, 4, (7,7), 1, True, True, False)\n",
        "  model = LSTMModel(config[\"input_size\"], config[\"hidden_size\"], config[\"num_layer\"], 1)\n",
        "  model.to(device)\n",
        "  criterion = torch.nn.MSELoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "  epoch_test_loss = 0\n",
        "\n",
        "  for epoch in range(config[\"epoch\"]):\n",
        "      epoch_test_loss = []\n",
        "      epoch_loss = []\n",
        "      model.train()\n",
        "      for batch_x, batch_y in train_loader:\n",
        "          batch_x = batch_x.to(device)\n",
        "          batch_y = batch_y.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          y_pred = model(batch_x)\n",
        "          loss = criterion(y_pred, batch_y).to(device)\n",
        "          loss.backward()\n",
        "          epoch_loss.append(loss.item())\n",
        "          optimizer.step()\n",
        "      epoch_loss = np.mean(epoch_loss)\n",
        "\n",
        "      model.eval()\n",
        "\n",
        "      with torch.no_grad():\n",
        "          for batch_test_x, batch_test_y in test_dataloader:\n",
        "              batch_test_x = batch_test_x.to(device)\n",
        "              batch_test_y = batch_test_y.to(device)\n",
        "              y_test_pred = model(batch_test_x)\n",
        "              test_loss = criterion(y_test_pred, batch_test_y).to(device)\n",
        "              epoch_test_loss.append(test_loss.item())\n",
        "          epoch_test_loss = np.mean(epoch_test_loss)\n",
        "\n",
        "      early_stopping(epoch_loss, epoch_test_loss)\n",
        "      if early_stopping.early_stop:\n",
        "        tune.report(loss = epoch_test_loss)\n",
        "        break\n",
        "\n",
        "      #os.makedirs(\"my_model\", exist_ok=True)\n",
        "      #torch.save((model.state_dict(), optimizer.state_dict()), \"my_model/checkpoint.pt\")\n",
        "      #checkpoint = Checkpoint.from_directory(\"my_model\")\n",
        "      tune.report(loss = epoch_test_loss)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xLg8huZFYnHK",
      "metadata": {
        "id": "xLg8huZFYnHK"
      },
      "outputs": [],
      "source": [
        "def test_best_model(best_result):\n",
        "    best_trained_model = LSTMModel(best_result.config[\"input_size\"], best_result.config[\"hidden_size\"], best_result.config[\"num_layer\"])\n",
        "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "    best_trained_model.to(device)\n",
        "\n",
        "    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
        "\n",
        "    model_state, optimizer_state = torch.load(checkpoint_path)\n",
        "    best_trained_model.load_state_dict(model_state)\n",
        "\n",
        "    test_ds = CustomDataset(test_data_tensor, test_target_tensor)\n",
        "    test_dataloader = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
        "\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in test_dataloader:\n",
        "            y_true += batch_y.tolist()\n",
        "            y_pred += model(batch_x).tolist()\n",
        "            print(y_pred)\n",
        "            break\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NYVQFpPTfEGS",
      "metadata": {
        "id": "NYVQFpPTfEGS"
      },
      "outputs": [],
      "source": [
        "data_path = \"/content/drive/MyDrive/master/data\"\n",
        "dataset_path = os.path.join(data_path, \"ready_dataset_.pickle\")\n",
        "ds_grace_path = os.path.join(data_path, \"ready_grace_dataset.pickle\")\n",
        "ds_297_path = os.path.join(data_path, \"ready_dataset_grace_single_297.pickle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c227f68-1191-4dbb-919b-921fd88a3646",
      "metadata": {
        "id": "3c227f68-1191-4dbb-919b-921fd88a3646"
      },
      "outputs": [],
      "source": [
        "data = pd.read_pickle(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tJg_ios5geNO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tJg_ios5geNO",
        "outputId": "6f2853ea-21d9-4dec-96b5-7ca1ce98269c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7756cbdd-54d8-403e-8bb2-af8d319adf64\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target_value</th>\n",
              "      <th>merged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.758333</td>\n",
              "      <td>[0.40286391973495483, 0.40286391973495483, 0.4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.883333</td>\n",
              "      <td>[0.612511396408081, 0.612511396408081, 0.63432...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.972222</td>\n",
              "      <td>[0.7316049337387085, 0.7316049337387085, 0.764...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>[0.8035080432891846, 0.8035080432891846, 0.806...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.947222</td>\n",
              "      <td>[0.9123387336730957, 0.9123387336730957, 0.912...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>0.483333</td>\n",
              "      <td>[0.3601520359516144, 0.3601520359516144, 0.354...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>0.338889</td>\n",
              "      <td>[0.5864202976226807, 0.5864202976226807, 0.588...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>0.144444</td>\n",
              "      <td>[0.7909024357795715, 0.7909024357795715, 0.794...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>0.366667</td>\n",
              "      <td>[0.8571354150772095, 0.8571354150772095, 0.860...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>0.219444</td>\n",
              "      <td>[0.9888230562210083, 0.9888230562210083, 0.991...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7756cbdd-54d8-403e-8bb2-af8d319adf64')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7756cbdd-54d8-403e-8bb2-af8d319adf64 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7756cbdd-54d8-403e-8bb2-af8d319adf64');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    target_value                                             merged\n",
              "0       0.758333  [0.40286391973495483, 0.40286391973495483, 0.4...\n",
              "1       0.883333  [0.612511396408081, 0.612511396408081, 0.63432...\n",
              "2       0.972222  [0.7316049337387085, 0.7316049337387085, 0.764...\n",
              "3       1.000000  [0.8035080432891846, 0.8035080432891846, 0.806...\n",
              "4       0.947222  [0.9123387336730957, 0.9123387336730957, 0.912...\n",
              "..           ...                                                ...\n",
              "85      0.483333  [0.3601520359516144, 0.3601520359516144, 0.354...\n",
              "86      0.338889  [0.5864202976226807, 0.5864202976226807, 0.588...\n",
              "87      0.144444  [0.7909024357795715, 0.7909024357795715, 0.794...\n",
              "88      0.366667  [0.8571354150772095, 0.8571354150772095, 0.860...\n",
              "89      0.219444  [0.9888230562210083, 0.9888230562210083, 0.991...\n",
              "\n",
              "[90 rows x 2 columns]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14155d1f",
      "metadata": {
        "id": "14155d1f"
      },
      "outputs": [],
      "source": [
        "data_arr = data.to_numpy()\n",
        "\n",
        "feat_data = data.loc[:, data.columns != \"target_value\"]\n",
        "target_data = data.loc[:, data.columns == \"target_value\"]\n",
        "\n",
        "feat_arr = feat_data.to_numpy()\n",
        "target_arr = target_data.to_numpy()\n",
        "\n",
        "target_arr = np.array(target_arr, dtype=np.float32).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_kAVypVsyr7V",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kAVypVsyr7V",
        "outputId": "252bfd4f-a0a8-45e3-f13d-e7b7bdef3916"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(90, 1)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_arr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "696217c2",
      "metadata": {
        "id": "696217c2"
      },
      "outputs": [],
      "source": [
        "#data_arr[0][8]\n",
        "data_arr_2 = []\n",
        "for row in feat_arr:\n",
        "    row = np.vstack(row)\n",
        "    row_2 = []\n",
        "    #for item in row:\n",
        "    #    item = item.reshape(8,13)\n",
        "    #    row_2.append(item)\n",
        "    data_arr_2.append(row)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1505195",
      "metadata": {
        "id": "c1505195"
      },
      "outputs": [],
      "source": [
        "target_arr_2 = []\n",
        "for row in target_arr:\n",
        "    row = np.hstack(row)\n",
        "    row_2 = []\n",
        "    for item in row:\n",
        "        target_arr_2.append(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d82b8766",
      "metadata": {
        "id": "d82b8766"
      },
      "outputs": [],
      "source": [
        "data_arr_2 = np.array(data_arr_2, dtype=np.float32)\n",
        "data_flatten = np.array([row.flatten() for row in data_arr_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0FmJXVvpbey_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FmJXVvpbey_",
        "outputId": "76d4762f-dc43-472b-e986-51f8663d01e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.40286392, 0.40286392, 0.4144625 , ..., 0.4146566 , 0.4146566 ,\n",
              "        0.4146566 ],\n",
              "       [0.6125114 , 0.6125114 , 0.6343278 , ..., 0.2683324 , 0.2683324 ,\n",
              "        0.2683324 ],\n",
              "       [0.73160493, 0.73160493, 0.7645573 , ..., 0.17917337, 0.17917337,\n",
              "        0.17917337],\n",
              "       ...,\n",
              "       [0.79090244, 0.79090244, 0.7946406 , ..., 0.6416968 , 0.6416968 ,\n",
              "        0.6416968 ],\n",
              "       [0.8571354 , 0.8571354 , 0.8600404 , ..., 0.6995308 , 0.6995308 ,\n",
              "        0.6995308 ],\n",
              "       [0.98882306, 0.98882306, 0.991624  , ..., 0.92073345, 0.92073345,\n",
              "        0.92073345]], dtype=float32)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d0b455b-cb2e-46fd-a1d7-e0b743239680",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d0b455b-cb2e-46fd-a1d7-e0b743239680",
        "outputId": "205c7466-af56-466a-9c09-984cd740d5c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(87, 1)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "seq_len = 4\n",
        "sequences = []\n",
        "targets = []\n",
        "flat_seq = []\n",
        "flat_targets = []\n",
        "\n",
        "for i in range(len(data_flatten) - seq_len + 1):\n",
        "        sequences.append(data_flatten[i:i + seq_len])  # Wyłączenie ostatniej kolumny (target) z sekwencji\n",
        "        targets.append(np.array([target_arr_2[i + seq_len-1]]))\n",
        "        flat_seq.append(data_flatten[i:i + seq_len].flatten())  # Wyłączenie ostatniej kolumny (target) z sekwencji\n",
        "        flat_targets.append(np.array([target_arr_2[i + seq_len-1]]).flatten())\n",
        "\n",
        "sequences = np.array(sequences, dtype=np.float32)\n",
        "targets = np.array(targets, dtype=np.float32)\n",
        "\n",
        "flat_seq = np.array(flat_seq, dtype=np.float32)\n",
        "flat_targets = np.array(flat_targets, dtype=np.float32)\n",
        "\n",
        "print(flat_targets.shape)\n",
        "train_sequences = sequences[:int(sequences.shape[0] * 0.7)]\n",
        "train_targets = targets[:int(targets.shape[0] * 0.7)]\n",
        "test_sequences = sequences[int(sequences.shape[0] * 0.7):]\n",
        "test_targets = targets[int(targets.shape[0] * 0.7):]\n",
        "\n",
        "train_flat_sequences = flat_seq[:int(flat_seq.shape[0] * 0.7)]\n",
        "train_flat_targets = flat_targets[:int(flat_targets.shape[0] * 0.7)]\n",
        "test_flat_sequences = flat_seq[int(flat_seq.shape[0] * 0.7):]\n",
        "test_flat_targets = flat_targets[int(flat_targets.shape[0] * 0.7):]\n",
        "\n",
        "data_tensor = torch.tensor(train_sequences, dtype=torch.float32)\n",
        "target_tensor = torch.tensor(train_targets, dtype=torch.float32)\n",
        "\n",
        "test_data_tensor = torch.tensor(test_sequences, dtype=torch.float32)\n",
        "test_target_tensor = torch.tensor(test_targets, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dSFdsYJZGmTE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSFdsYJZGmTE",
        "outputId": "a9f91adf-50be-4379-8b72-714c678a4e53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 832)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequences[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca443a28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca443a28",
        "outputId": "723cf2bf-f013-4c25-f6e4-07ee1095f745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pK1wwZ54jHHV",
      "metadata": {
        "id": "pK1wwZ54jHHV"
      },
      "outputs": [],
      "source": [
        "ds = CustomDataset(data_tensor, target_tensor)\n",
        "test_ds = CustomDataset(test_data_tensor, test_target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5F6x5IVzp4IS",
      "metadata": {
        "id": "5F6x5IVzp4IS"
      },
      "outputs": [],
      "source": [
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iCAlFHih_2Ox",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCAlFHih_2Ox",
        "outputId": "56274744-2cb6-4612-80c6-b7b17b6447f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-09 21:47:26,893\tWARNING services.py:1826 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 6101663744 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
            "2023-07-09 21:47:27,961\tINFO worker.py:1636 -- Started a local Ray instance.\n",
            "2023-07-09 21:47:30,184\tWARNING callback.py:144 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Current time: 2023-07-09 21:47:31 (running for 00:00:01.11)\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 512.000: None | Iter 256.000: None | Iter 128.000: None | Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Logical resource usage: 0/2 CPUs, 0/1 GPUs\n",
            "Result logdir: /root/ray_results/train_fn_2023-07-09_21-47-30\n",
            "Number of trials: 16/100 (16 PENDING)\n",
            "+----------------------+----------+-------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+\n",
            "| Trial name           | status   | loc   |   batch_size |   epoch |   hidden_size |   learning_rate |   min_delta |   num_layer |   tolerance |\n",
            "|----------------------+----------+-------+--------------+---------+---------------+-----------------+-------------+-------------+-------------|\n",
            "| train_fn_340c8_00000 | PENDING  |       |           64 |    1000 |           256 |      0.0249397  |           2 |           1 |           5 |\n",
            "| train_fn_340c8_00001 | PENDING  |       |           32 |    1000 |             1 |      0.00721557 |           5 |           1 |           5 |\n",
            "| train_fn_340c8_00002 | PENDING  |       |           16 |    1000 |             4 |      0.0382463  |           5 |           2 |           5 |\n",
            "| train_fn_340c8_00003 | PENDING  |       |           32 |      60 |             4 |      0.0624976  |           3 |           3 |           5 |\n",
            "| train_fn_340c8_00004 | PENDING  |       |           64 |    1000 |           256 |      0.0986488  |           1 |           1 |           2 |\n",
            "| train_fn_340c8_00005 | PENDING  |       |           32 |      80 |             1 |      0.0436456  |          30 |           7 |           3 |\n",
            "| train_fn_340c8_00006 | PENDING  |       |           32 |     500 |            64 |      0.0182318  |          25 |           7 |           1 |\n",
            "| train_fn_340c8_00007 | PENDING  |       |           64 |      60 |            16 |      0.0212547  |          15 |           8 |           2 |\n",
            "| train_fn_340c8_00008 | PENDING  |       |           16 |      80 |             4 |      0.0194434  |          15 |           6 |           2 |\n",
            "| train_fn_340c8_00009 | PENDING  |       |           64 |      80 |             2 |      0.00587327 |          25 |           1 |           4 |\n",
            "| train_fn_340c8_00010 | PENDING  |       |           32 |     150 |           256 |      0.0136777  |          30 |           7 |           5 |\n",
            "| train_fn_340c8_00011 | PENDING  |       |           16 |      80 |            64 |      0.0171157  |           5 |           7 |           4 |\n",
            "| train_fn_340c8_00012 | PENDING  |       |           16 |     150 |           256 |      0.00852635 |          20 |           3 |           1 |\n",
            "| train_fn_340c8_00013 | PENDING  |       |           16 |     100 |            32 |      0.0240211  |          30 |           1 |           1 |\n",
            "| train_fn_340c8_00014 | PENDING  |       |           32 |     700 |            32 |      0.0486621  |           1 |           3 |           5 |\n",
            "| train_fn_340c8_00015 | PENDING  |       |           16 |     100 |             8 |      0.00636152 |          25 |           5 |           3 |\n",
            "+----------------------+----------+-------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+\n",
            "\n",
            "\n",
            "Result for train_fn_340c8_00000:\n",
            "  date: 2023-07-09_21-47-35\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 46.158348083496094\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.5968079566955566\n",
            "  time_this_iter_s: 0.5968079566955566\n",
            "  time_total_s: 0.5968079566955566\n",
            "  timestamp: 1688939255\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00000\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2023-07-09 21:47:36 (running for 00:00:06.11)\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 512.000: None | Iter 256.000: None | Iter 128.000: None | Iter 64.000: None | Iter 32.000: None | Iter 16.000: -5.596081733703613 | Iter 8.000: -8.722282409667969 | Iter 4.000: -0.5950481295585632 | Iter 2.000: -18.05712890625 | Iter 1.000: -46.158348083496094\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs\n",
            "Current best trial: 340c8_00000 with loss=0.7698913216590881 and parameters={'batch_size': 64, 'hidden_size': 256, 'num_layer': 1, 'epoch': 1000, 'learning_rate': 0.024939661116205266, 'ds': <__main__.CustomDataset object at 0x7f6fe875ed70>, 'test_ds': <__main__.CustomDataset object at 0x7f6fe875cac0>, 'input_size': 832, 'tolerance': 5, 'min_delta': 2}\n",
            "Result logdir: /root/ray_results/train_fn_2023-07-09_21-47-30\n",
            "Number of trials: 17/100 (16 PENDING, 1 RUNNING)\n",
            "+----------------------+----------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+----------+\n",
            "| Trial name           | status   | loc               |   batch_size |   epoch |   hidden_size |   learning_rate |   min_delta |   num_layer |   tolerance |   iter |   total time (s) |     loss |\n",
            "|----------------------+----------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+----------|\n",
            "| train_fn_340c8_00000 | RUNNING  | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0249397  |           2 |           1 |           5 |     25 |         0.983699 | 0.769891 |\n",
            "| train_fn_340c8_00001 | PENDING  |                   |           32 |    1000 |             1 |      0.00721557 |           5 |           1 |           5 |        |                  |          |\n",
            "| train_fn_340c8_00002 | PENDING  |                   |           16 |    1000 |             4 |      0.0382463  |           5 |           2 |           5 |        |                  |          |\n",
            "| train_fn_340c8_00003 | PENDING  |                   |           32 |      60 |             4 |      0.0624976  |           3 |           3 |           5 |        |                  |          |\n",
            "| train_fn_340c8_00004 | PENDING  |                   |           64 |    1000 |           256 |      0.0986488  |           1 |           1 |           2 |        |                  |          |\n",
            "| train_fn_340c8_00005 | PENDING  |                   |           32 |      80 |             1 |      0.0436456  |          30 |           7 |           3 |        |                  |          |\n",
            "| train_fn_340c8_00006 | PENDING  |                   |           32 |     500 |            64 |      0.0182318  |          25 |           7 |           1 |        |                  |          |\n",
            "| train_fn_340c8_00007 | PENDING  |                   |           64 |      60 |            16 |      0.0212547  |          15 |           8 |           2 |        |                  |          |\n",
            "| train_fn_340c8_00008 | PENDING  |                   |           16 |      80 |             4 |      0.0194434  |          15 |           6 |           2 |        |                  |          |\n",
            "| train_fn_340c8_00009 | PENDING  |                   |           64 |      80 |             2 |      0.00587327 |          25 |           1 |           4 |        |                  |          |\n",
            "| train_fn_340c8_00010 | PENDING  |                   |           32 |     150 |           256 |      0.0136777  |          30 |           7 |           5 |        |                  |          |\n",
            "| train_fn_340c8_00011 | PENDING  |                   |           16 |      80 |            64 |      0.0171157  |           5 |           7 |           4 |        |                  |          |\n",
            "| train_fn_340c8_00012 | PENDING  |                   |           16 |     150 |           256 |      0.00852635 |          20 |           3 |           1 |        |                  |          |\n",
            "| train_fn_340c8_00013 | PENDING  |                   |           16 |     100 |            32 |      0.0240211  |          30 |           1 |           1 |        |                  |          |\n",
            "| train_fn_340c8_00014 | PENDING  |                   |           32 |     700 |            32 |      0.0486621  |           1 |           3 |           5 |        |                  |          |\n",
            "| train_fn_340c8_00015 | PENDING  |                   |           16 |     100 |             8 |      0.00636152 |          25 |           5 |           3 |        |                  |          |\n",
            "| train_fn_340c8_00016 | PENDING  |                   |           64 |     500 |             4 |      0.022412   |          15 |           7 |           3 |        |                  |          |\n",
            "+----------------------+----------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+----------+\n",
            "\n",
            "\n",
            "Result for train_fn_340c8_00000:\n",
            "  date: 2023-07-09_21-47-40\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 315\n",
            "  loss: 0.09394951164722443\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 5.611483812332153\n",
            "  time_this_iter_s: 0.014519691467285156\n",
            "  time_total_s: 5.611483812332153\n",
            "  timestamp: 1688939260\n",
            "  training_iteration: 315\n",
            "  trial_id: 340c8_00000\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2023-07-09 21:47:41 (running for 00:00:11.12)\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 512.000: None | Iter 256.000: -0.09394465386867523 | Iter 128.000: -0.09052281826734543 | Iter 64.000: -0.0799851194024086 | Iter 32.000: -1.5240309238433838 | Iter 16.000: -5.596081733703613 | Iter 8.000: -8.722282409667969 | Iter 4.000: -0.5950481295585632 | Iter 2.000: -18.05712890625 | Iter 1.000: -46.158348083496094\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs\n",
            "Current best trial: 340c8_00000 with loss=0.09394926577806473 and parameters={'batch_size': 64, 'hidden_size': 256, 'num_layer': 1, 'epoch': 1000, 'learning_rate': 0.024939661116205266, 'ds': <__main__.CustomDataset object at 0x7f6ff00cb970>, 'test_ds': <__main__.CustomDataset object at 0x7f6fe8720790>, 'input_size': 832, 'tolerance': 5, 'min_delta': 2}\n",
            "Result logdir: /root/ray_results/train_fn_2023-07-09_21-47-30\n",
            "Number of trials: 17/100 (16 PENDING, 1 RUNNING)\n",
            "+----------------------+----------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-----------+\n",
            "| Trial name           | status   | loc               |   batch_size |   epoch |   hidden_size |   learning_rate |   min_delta |   num_layer |   tolerance |   iter |   total time (s) |      loss |\n",
            "|----------------------+----------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-----------|\n",
            "| train_fn_340c8_00000 | RUNNING  | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0249397  |           2 |           1 |           5 |    333 |          5.99141 | 0.0939493 |\n",
            "| train_fn_340c8_00001 | PENDING  |                   |           32 |    1000 |             1 |      0.00721557 |           5 |           1 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00002 | PENDING  |                   |           16 |    1000 |             4 |      0.0382463  |           5 |           2 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00003 | PENDING  |                   |           32 |      60 |             4 |      0.0624976  |           3 |           3 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00004 | PENDING  |                   |           64 |    1000 |           256 |      0.0986488  |           1 |           1 |           2 |        |                  |           |\n",
            "| train_fn_340c8_00005 | PENDING  |                   |           32 |      80 |             1 |      0.0436456  |          30 |           7 |           3 |        |                  |           |\n",
            "| train_fn_340c8_00006 | PENDING  |                   |           32 |     500 |            64 |      0.0182318  |          25 |           7 |           1 |        |                  |           |\n",
            "| train_fn_340c8_00007 | PENDING  |                   |           64 |      60 |            16 |      0.0212547  |          15 |           8 |           2 |        |                  |           |\n",
            "| train_fn_340c8_00008 | PENDING  |                   |           16 |      80 |             4 |      0.0194434  |          15 |           6 |           2 |        |                  |           |\n",
            "| train_fn_340c8_00009 | PENDING  |                   |           64 |      80 |             2 |      0.00587327 |          25 |           1 |           4 |        |                  |           |\n",
            "| train_fn_340c8_00010 | PENDING  |                   |           32 |     150 |           256 |      0.0136777  |          30 |           7 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00011 | PENDING  |                   |           16 |      80 |            64 |      0.0171157  |           5 |           7 |           4 |        |                  |           |\n",
            "| train_fn_340c8_00012 | PENDING  |                   |           16 |     150 |           256 |      0.00852635 |          20 |           3 |           1 |        |                  |           |\n",
            "| train_fn_340c8_00013 | PENDING  |                   |           16 |     100 |            32 |      0.0240211  |          30 |           1 |           1 |        |                  |           |\n",
            "| train_fn_340c8_00014 | PENDING  |                   |           32 |     700 |            32 |      0.0486621  |           1 |           3 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00015 | PENDING  |                   |           16 |     100 |             8 |      0.00636152 |          25 |           5 |           3 |        |                  |           |\n",
            "| train_fn_340c8_00016 | PENDING  |                   |           64 |     500 |             4 |      0.022412   |          15 |           7 |           3 |        |                  |           |\n",
            "+----------------------+----------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-----------+\n",
            "\n",
            "\n",
            "Result for train_fn_340c8_00000:\n",
            "  date: 2023-07-09_21-47-45\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 581\n",
            "  loss: 0.09394923597574234\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 10.62165093421936\n",
            "  time_this_iter_s: 0.021775245666503906\n",
            "  time_total_s: 10.62165093421936\n",
            "  timestamp: 1688939265\n",
            "  training_iteration: 581\n",
            "  trial_id: 340c8_00000\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2023-07-09 21:47:46 (running for 00:00:16.48)\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 512.000: -0.09394926577806473 | Iter 256.000: -0.09394465386867523 | Iter 128.000: -0.09052281826734543 | Iter 64.000: -0.0799851194024086 | Iter 32.000: -1.5240309238433838 | Iter 16.000: -5.596081733703613 | Iter 8.000: -8.722282409667969 | Iter 4.000: -0.5950481295585632 | Iter 2.000: -18.05712890625 | Iter 1.000: -46.158348083496094\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs\n",
            "Current best trial: 340c8_00000 with loss=0.09394923597574234 and parameters={'batch_size': 64, 'hidden_size': 256, 'num_layer': 1, 'epoch': 1000, 'learning_rate': 0.024939661116205266, 'ds': <__main__.CustomDataset object at 0x7f6fe85d30a0>, 'test_ds': <__main__.CustomDataset object at 0x7f6ff004f460>, 'input_size': 832, 'tolerance': 5, 'min_delta': 2}\n",
            "Result logdir: /root/ray_results/train_fn_2023-07-09_21-47-30\n",
            "Number of trials: 17/100 (16 PENDING, 1 RUNNING)\n",
            "+----------------------+----------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-----------+\n",
            "| Trial name           | status   | loc               |   batch_size |   epoch |   hidden_size |   learning_rate |   min_delta |   num_layer |   tolerance |   iter |   total time (s) |      loss |\n",
            "|----------------------+----------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-----------|\n",
            "| train_fn_340c8_00000 | RUNNING  | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0249397  |           2 |           1 |           5 |    588 |          10.7628 | 0.0939492 |\n",
            "| train_fn_340c8_00001 | PENDING  |                   |           32 |    1000 |             1 |      0.00721557 |           5 |           1 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00002 | PENDING  |                   |           16 |    1000 |             4 |      0.0382463  |           5 |           2 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00003 | PENDING  |                   |           32 |      60 |             4 |      0.0624976  |           3 |           3 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00004 | PENDING  |                   |           64 |    1000 |           256 |      0.0986488  |           1 |           1 |           2 |        |                  |           |\n",
            "| train_fn_340c8_00005 | PENDING  |                   |           32 |      80 |             1 |      0.0436456  |          30 |           7 |           3 |        |                  |           |\n",
            "| train_fn_340c8_00006 | PENDING  |                   |           32 |     500 |            64 |      0.0182318  |          25 |           7 |           1 |        |                  |           |\n",
            "| train_fn_340c8_00007 | PENDING  |                   |           64 |      60 |            16 |      0.0212547  |          15 |           8 |           2 |        |                  |           |\n",
            "| train_fn_340c8_00008 | PENDING  |                   |           16 |      80 |             4 |      0.0194434  |          15 |           6 |           2 |        |                  |           |\n",
            "| train_fn_340c8_00009 | PENDING  |                   |           64 |      80 |             2 |      0.00587327 |          25 |           1 |           4 |        |                  |           |\n",
            "| train_fn_340c8_00010 | PENDING  |                   |           32 |     150 |           256 |      0.0136777  |          30 |           7 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00011 | PENDING  |                   |           16 |      80 |            64 |      0.0171157  |           5 |           7 |           4 |        |                  |           |\n",
            "| train_fn_340c8_00012 | PENDING  |                   |           16 |     150 |           256 |      0.00852635 |          20 |           3 |           1 |        |                  |           |\n",
            "| train_fn_340c8_00013 | PENDING  |                   |           16 |     100 |            32 |      0.0240211  |          30 |           1 |           1 |        |                  |           |\n",
            "| train_fn_340c8_00014 | PENDING  |                   |           32 |     700 |            32 |      0.0486621  |           1 |           3 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00015 | PENDING  |                   |           16 |     100 |             8 |      0.00636152 |          25 |           5 |           3 |        |                  |           |\n",
            "| train_fn_340c8_00016 | PENDING  |                   |           64 |     500 |             4 |      0.022412   |          15 |           7 |           3 |        |                  |           |\n",
            "+----------------------+----------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-----------+\n",
            "\n",
            "\n",
            "Result for train_fn_340c8_00000:\n",
            "  date: 2023-07-09_21-47-50\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 794\n",
            "  loss: 0.09394923597574234\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 15.63156795501709\n",
            "  time_this_iter_s: 0.018115520477294922\n",
            "  time_total_s: 15.63156795501709\n",
            "  timestamp: 1688939270\n",
            "  training_iteration: 794\n",
            "  trial_id: 340c8_00000\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2023-07-09 21:47:51 (running for 00:00:21.48)\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 512.000: -0.09394926577806473 | Iter 256.000: -0.09394465386867523 | Iter 128.000: -0.09052281826734543 | Iter 64.000: -0.0799851194024086 | Iter 32.000: -1.5240309238433838 | Iter 16.000: -5.596081733703613 | Iter 8.000: -8.722282409667969 | Iter 4.000: -0.5950481295585632 | Iter 2.000: -18.05712890625 | Iter 1.000: -46.158348083496094\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs\n",
            "Current best trial: 340c8_00000 with loss=0.09394923597574234 and parameters={'batch_size': 64, 'hidden_size': 256, 'num_layer': 1, 'epoch': 1000, 'learning_rate': 0.024939661116205266, 'ds': <__main__.CustomDataset object at 0x7f6fe8785390>, 'test_ds': <__main__.CustomDataset object at 0x7f6fe8785900>, 'input_size': 832, 'tolerance': 5, 'min_delta': 2}\n",
            "Result logdir: /root/ray_results/train_fn_2023-07-09_21-47-30\n",
            "Number of trials: 17/100 (16 PENDING, 1 RUNNING)\n",
            "+----------------------+----------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-----------+\n",
            "| Trial name           | status   | loc               |   batch_size |   epoch |   hidden_size |   learning_rate |   min_delta |   num_layer |   tolerance |   iter |   total time (s) |      loss |\n",
            "|----------------------+----------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-----------|\n",
            "| train_fn_340c8_00000 | RUNNING  | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0249397  |           2 |           1 |           5 |    838 |          16.3511 | 0.0939492 |\n",
            "| train_fn_340c8_00001 | PENDING  |                   |           32 |    1000 |             1 |      0.00721557 |           5 |           1 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00002 | PENDING  |                   |           16 |    1000 |             4 |      0.0382463  |           5 |           2 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00003 | PENDING  |                   |           32 |      60 |             4 |      0.0624976  |           3 |           3 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00004 | PENDING  |                   |           64 |    1000 |           256 |      0.0986488  |           1 |           1 |           2 |        |                  |           |\n",
            "| train_fn_340c8_00005 | PENDING  |                   |           32 |      80 |             1 |      0.0436456  |          30 |           7 |           3 |        |                  |           |\n",
            "| train_fn_340c8_00006 | PENDING  |                   |           32 |     500 |            64 |      0.0182318  |          25 |           7 |           1 |        |                  |           |\n",
            "| train_fn_340c8_00007 | PENDING  |                   |           64 |      60 |            16 |      0.0212547  |          15 |           8 |           2 |        |                  |           |\n",
            "| train_fn_340c8_00008 | PENDING  |                   |           16 |      80 |             4 |      0.0194434  |          15 |           6 |           2 |        |                  |           |\n",
            "| train_fn_340c8_00009 | PENDING  |                   |           64 |      80 |             2 |      0.00587327 |          25 |           1 |           4 |        |                  |           |\n",
            "| train_fn_340c8_00010 | PENDING  |                   |           32 |     150 |           256 |      0.0136777  |          30 |           7 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00011 | PENDING  |                   |           16 |      80 |            64 |      0.0171157  |           5 |           7 |           4 |        |                  |           |\n",
            "| train_fn_340c8_00012 | PENDING  |                   |           16 |     150 |           256 |      0.00852635 |          20 |           3 |           1 |        |                  |           |\n",
            "| train_fn_340c8_00013 | PENDING  |                   |           16 |     100 |            32 |      0.0240211  |          30 |           1 |           1 |        |                  |           |\n",
            "| train_fn_340c8_00014 | PENDING  |                   |           32 |     700 |            32 |      0.0486621  |           1 |           3 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00015 | PENDING  |                   |           16 |     100 |             8 |      0.00636152 |          25 |           5 |           3 |        |                  |           |\n",
            "| train_fn_340c8_00016 | PENDING  |                   |           64 |     500 |             4 |      0.022412   |          15 |           7 |           3 |        |                  |           |\n",
            "+----------------------+----------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-----------+\n",
            "\n",
            "\n",
            "Result for train_fn_340c8_00000:\n",
            "  date: 2023-07-09_21-47-54\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1000\n",
            "  loss: 0.09394923597574234\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 19.12657356262207\n",
            "  time_this_iter_s: 0.014373064041137695\n",
            "  time_total_s: 19.12657356262207\n",
            "  timestamp: 1688939274\n",
            "  training_iteration: 1000\n",
            "  trial_id: 340c8_00000\n",
            "  \n",
            "Trial train_fn_340c8_00000 completed.\n",
            "Result for train_fn_340c8_00001:\n",
            "  date: 2023-07-09_21-47-54\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.40687641501426697\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.07888436317443848\n",
            "  time_this_iter_s: 0.07888436317443848\n",
            "  time_total_s: 0.07888436317443848\n",
            "  timestamp: 1688939274\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00001\n",
            "  \n",
            "Result for train_fn_340c8_00001:\n",
            "  date: 2023-07-09_21-47-55\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 64\n",
            "  loss: 0.09432914853096008\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 1.1689701080322266\n",
            "  time_this_iter_s: 0.015100717544555664\n",
            "  time_total_s: 1.1689701080322266\n",
            "  timestamp: 1688939275\n",
            "  training_iteration: 64\n",
            "  trial_id: 340c8_00001\n",
            "  \n",
            "Trial train_fn_340c8_00001 completed.\n",
            "Result for train_fn_340c8_00002:\n",
            "  date: 2023-07-09_21-47-55\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.07924488931894302\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.02756023406982422\n",
            "  time_this_iter_s: 0.02756023406982422\n",
            "  time_total_s: 0.02756023406982422\n",
            "  timestamp: 1688939275\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00002\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2023-07-09 21:47:56 (running for 00:00:26.50)\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 512.000: -0.09394926577806473 | Iter 256.000: -0.09394465386867523 | Iter 128.000: -0.09052281826734543 | Iter 64.000: -0.08715713396668434 | Iter 32.000: -0.10130759701132774 | Iter 16.000: -0.10711735859513283 | Iter 8.000: -0.1281609758734703 | Iter 4.000: -0.14592353999614716 | Iter 2.000: -0.3341270461678505 | Iter 1.000: -0.40687641501426697\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs\n",
            "Current best trial: 340c8_00000 with loss=0.09394923597574234 and parameters={'batch_size': 64, 'hidden_size': 256, 'num_layer': 1, 'epoch': 1000, 'learning_rate': 0.024939661116205266, 'ds': <__main__.CustomDataset object at 0x7f6fe85e49a0>, 'test_ds': <__main__.CustomDataset object at 0x7f6fe85ed870>, 'input_size': 832, 'tolerance': 5, 'min_delta': 2}\n",
            "Result logdir: /root/ray_results/train_fn_2023-07-09_21-47-30\n",
            "Number of trials: 19/100 (16 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-----------+\n",
            "| Trial name           | status     | loc               |   batch_size |   epoch |   hidden_size |   learning_rate |   min_delta |   num_layer |   tolerance |   iter |   total time (s) |      loss |\n",
            "|----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-----------|\n",
            "| train_fn_340c8_00002 | RUNNING    | 172.28.0.12:18804 |           16 |    1000 |             4 |      0.0382463  |           5 |           2 |           5 |     45 |         0.964336 | 0.100703  |\n",
            "| train_fn_340c8_00003 | PENDING    |                   |           32 |      60 |             4 |      0.0624976  |           3 |           3 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00004 | PENDING    |                   |           64 |    1000 |           256 |      0.0986488  |           1 |           1 |           2 |        |                  |           |\n",
            "| train_fn_340c8_00005 | PENDING    |                   |           32 |      80 |             1 |      0.0436456  |          30 |           7 |           3 |        |                  |           |\n",
            "| train_fn_340c8_00006 | PENDING    |                   |           32 |     500 |            64 |      0.0182318  |          25 |           7 |           1 |        |                  |           |\n",
            "| train_fn_340c8_00007 | PENDING    |                   |           64 |      60 |            16 |      0.0212547  |          15 |           8 |           2 |        |                  |           |\n",
            "| train_fn_340c8_00008 | PENDING    |                   |           16 |      80 |             4 |      0.0194434  |          15 |           6 |           2 |        |                  |           |\n",
            "| train_fn_340c8_00009 | PENDING    |                   |           64 |      80 |             2 |      0.00587327 |          25 |           1 |           4 |        |                  |           |\n",
            "| train_fn_340c8_00010 | PENDING    |                   |           32 |     150 |           256 |      0.0136777  |          30 |           7 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00011 | PENDING    |                   |           16 |      80 |            64 |      0.0171157  |           5 |           7 |           4 |        |                  |           |\n",
            "| train_fn_340c8_00012 | PENDING    |                   |           16 |     150 |           256 |      0.00852635 |          20 |           3 |           1 |        |                  |           |\n",
            "| train_fn_340c8_00013 | PENDING    |                   |           16 |     100 |            32 |      0.0240211  |          30 |           1 |           1 |        |                  |           |\n",
            "| train_fn_340c8_00014 | PENDING    |                   |           32 |     700 |            32 |      0.0486621  |           1 |           3 |           5 |        |                  |           |\n",
            "| train_fn_340c8_00015 | PENDING    |                   |           16 |     100 |             8 |      0.00636152 |          25 |           5 |           3 |        |                  |           |\n",
            "| train_fn_340c8_00016 | PENDING    |                   |           64 |     500 |             4 |      0.022412   |          15 |           7 |           3 |        |                  |           |\n",
            "| train_fn_340c8_00017 | PENDING    |                   |           64 |     500 |            32 |      0.021546   |           2 |           5 |           3 |        |                  |           |\n",
            "| train_fn_340c8_00018 | PENDING    |                   |           32 |     150 |             2 |      0.0859522  |          25 |           6 |           3 |        |                  |           |\n",
            "| train_fn_340c8_00000 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0249397  |           2 |           1 |           5 |   1000 |        19.1266   | 0.0939492 |\n",
            "| train_fn_340c8_00001 | TERMINATED | 172.28.0.12:18804 |           32 |    1000 |             1 |      0.00721557 |           5 |           1 |           5 |     64 |         1.16897  | 0.0943291 |\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-----------+\n",
            "\n",
            "\n",
            "Result for train_fn_340c8_00002:\n",
            "  date: 2023-07-09_21-47-57\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 64\n",
            "  loss: 0.100223608314991\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 1.38149094581604\n",
            "  time_this_iter_s: 0.020662546157836914\n",
            "  time_total_s: 1.38149094581604\n",
            "  timestamp: 1688939277\n",
            "  training_iteration: 64\n",
            "  trial_id: 340c8_00002\n",
            "  \n",
            "Trial train_fn_340c8_00002 completed.\n",
            "Result for train_fn_340c8_00003:\n",
            "  date: 2023-07-09_21-47-57\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.18733611702919006\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.013621807098388672\n",
            "  time_this_iter_s: 0.013621807098388672\n",
            "  time_total_s: 0.013621807098388672\n",
            "  timestamp: 1688939277\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00003\n",
            "  \n",
            "Result for train_fn_340c8_00003:\n",
            "  date: 2023-07-09_21-47-58\n",
            "  done: true\n",
            "  experiment_tag: 3_batch_size=32,epoch=60,hidden_size=4,learning_rate=0.0625,min_delta=3,num_layer=3,tolerance=5\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 60\n",
            "  loss: 0.09291137009859085\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 1.5600416660308838\n",
            "  time_this_iter_s: 0.015732288360595703\n",
            "  time_total_s: 1.5600416660308838\n",
            "  timestamp: 1688939278\n",
            "  training_iteration: 60\n",
            "  trial_id: 340c8_00003\n",
            "  \n",
            "Trial train_fn_340c8_00003 completed.\n",
            "Result for train_fn_340c8_00004:\n",
            "  date: 2023-07-09_21-47-58\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 307.63079833984375\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.020978927612304688\n",
            "  time_this_iter_s: 0.020978927612304688\n",
            "  time_total_s: 0.020978927612304688\n",
            "  timestamp: 1688939278\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00004\n",
            "  \n",
            "Trial train_fn_340c8_00004 completed.\n",
            "Result for train_fn_340c8_00005:\n",
            "  date: 2023-07-09_21-47-58\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.04460036754608154\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.020320415496826172\n",
            "  time_this_iter_s: 0.020320415496826172\n",
            "  time_total_s: 0.020320415496826172\n",
            "  timestamp: 1688939278\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00005\n",
            "  \n",
            "Result for train_fn_340c8_00005:\n",
            "  date: 2023-07-09_21-47-58\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.1649523824453354\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.0798790454864502\n",
            "  time_this_iter_s: 0.01809835433959961\n",
            "  time_total_s: 0.0798790454864502\n",
            "  timestamp: 1688939278\n",
            "  training_iteration: 4\n",
            "  trial_id: 340c8_00005\n",
            "  \n",
            "Trial train_fn_340c8_00005 completed.\n",
            "Result for train_fn_340c8_00006:\n",
            "  date: 2023-07-09_21-47-58\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 2.2637081146240234\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.02913665771484375\n",
            "  time_this_iter_s: 0.02913665771484375\n",
            "  time_total_s: 0.02913665771484375\n",
            "  timestamp: 1688939278\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00006\n",
            "  \n",
            "Trial train_fn_340c8_00006 completed.\n",
            "Result for train_fn_340c8_00007:\n",
            "  date: 2023-07-09_21-47-58\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.03074502944946289\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.016111135482788086\n",
            "  time_this_iter_s: 0.016111135482788086\n",
            "  time_total_s: 0.016111135482788086\n",
            "  timestamp: 1688939278\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00007\n",
            "  \n",
            "Result for train_fn_340c8_00007:\n",
            "  date: 2023-07-09_21-47-59\n",
            "  done: true\n",
            "  experiment_tag: 7_batch_size=64,epoch=60,hidden_size=16,learning_rate=0.0213,min_delta=15,num_layer=8,tolerance=2\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 60\n",
            "  loss: 0.09320159256458282\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.9158470630645752\n",
            "  time_this_iter_s: 0.025646209716796875\n",
            "  time_total_s: 0.9158470630645752\n",
            "  timestamp: 1688939279\n",
            "  training_iteration: 60\n",
            "  trial_id: 340c8_00007\n",
            "  \n",
            "Trial train_fn_340c8_00007 completed.\n",
            "Result for train_fn_340c8_00008:\n",
            "  date: 2023-07-09_21-47-59\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.08602668344974518\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.024637699127197266\n",
            "  time_this_iter_s: 0.024637699127197266\n",
            "  time_total_s: 0.024637699127197266\n",
            "  timestamp: 1688939279\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00008\n",
            "  \n",
            "Result for train_fn_340c8_00008:\n",
            "  date: 2023-07-09_21-48-00\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.1773114763200283\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.06141257286071777\n",
            "  time_this_iter_s: 0.03677487373352051\n",
            "  time_total_s: 0.06141257286071777\n",
            "  timestamp: 1688939280\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00008\n",
            "  \n",
            "Trial train_fn_340c8_00008 completed.\n",
            "Result for train_fn_340c8_00009:\n",
            "  date: 2023-07-09_21-48-00\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.4416603446006775\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.02467942237854004\n",
            "  time_this_iter_s: 0.02467942237854004\n",
            "  time_total_s: 0.02467942237854004\n",
            "  timestamp: 1688939280\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00009\n",
            "  \n",
            "Trial train_fn_340c8_00009 completed.\n",
            "Result for train_fn_340c8_00010:\n",
            "  date: 2023-07-09_21-48-00\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 2.037001132965088\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.10084795951843262\n",
            "  time_this_iter_s: 0.10084795951843262\n",
            "  time_total_s: 0.10084795951843262\n",
            "  timestamp: 1688939280\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00010\n",
            "  \n",
            "Trial train_fn_340c8_00010 completed.\n",
            "Result for train_fn_340c8_00011:\n",
            "  date: 2023-07-09_21-48-00\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.032819957472383976\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.033117055892944336\n",
            "  time_this_iter_s: 0.033117055892944336\n",
            "  time_total_s: 0.033117055892944336\n",
            "  timestamp: 1688939280\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00011\n",
            "  \n",
            "Result for train_fn_340c8_00011:\n",
            "  date: 2023-07-09_21-48-01\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 32\n",
            "  loss: 0.10024634376168251\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 1.1286108493804932\n",
            "  time_this_iter_s: 0.037543296813964844\n",
            "  time_total_s: 1.1286108493804932\n",
            "  timestamp: 1688939281\n",
            "  training_iteration: 32\n",
            "  trial_id: 340c8_00011\n",
            "  \n",
            "Trial train_fn_340c8_00011 completed.\n",
            "Result for train_fn_340c8_00012:\n",
            "  date: 2023-07-09_21-48-01\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.04591689445078373\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.08682751655578613\n",
            "  time_this_iter_s: 0.08682751655578613\n",
            "  time_total_s: 0.08682751655578613\n",
            "  timestamp: 1688939281\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00012\n",
            "  \n",
            "Result for train_fn_340c8_00012:\n",
            "  date: 2023-07-09_21-48-01\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.1696375347673893\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.1966562271118164\n",
            "  time_this_iter_s: 0.04260087013244629\n",
            "  time_total_s: 0.1966562271118164\n",
            "  timestamp: 1688939281\n",
            "  training_iteration: 4\n",
            "  trial_id: 340c8_00012\n",
            "  \n",
            "Trial train_fn_340c8_00012 completed.\n",
            "== Status ==\n",
            "Current time: 2023-07-09 21:48:01 (running for 00:00:31.53)\n",
            "Using AsyncHyperBand: num_stopped=11\n",
            "Bracket: Iter 512.000: -0.09394926577806473 | Iter 256.000: -0.09394465386867523 | Iter 128.000: -0.09052281826734543 | Iter 64.000: -0.09432914853096008 | Iter 32.000: -0.0976253803819418 | Iter 16.000: -0.10302988160401583 | Iter 8.000: -0.11251168604940176 | Iter 4.000: -0.1347818449139595 | Iter 2.000: -0.14390884339809418 | Iter 1.000: -0.18733611702919006\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs\n",
            "Current best trial: 340c8_00003 with loss=0.09291137009859085 and parameters={'batch_size': 32, 'hidden_size': 4, 'num_layer': 3, 'epoch': 60, 'learning_rate': 0.06249763558113424, 'ds': <__main__.CustomDataset object at 0x7f6fe87227a0>, 'test_ds': <__main__.CustomDataset object at 0x7f6ff0d25330>, 'input_size': 832, 'tolerance': 5, 'min_delta': 3}\n",
            "Result logdir: /root/ray_results/train_fn_2023-07-09_21-47-30\n",
            "Number of trials: 29/100 (16 PENDING, 13 TERMINATED)\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "| Trial name           | status     | loc               |   batch_size |   epoch |   hidden_size |   learning_rate |   min_delta |   num_layer |   tolerance |   iter |   total time (s) |        loss |\n",
            "|----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------|\n",
            "| train_fn_340c8_00013 | PENDING    |                   |           16 |     100 |            32 |      0.0240211  |          30 |           1 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00014 | PENDING    |                   |           32 |     700 |            32 |      0.0486621  |           1 |           3 |           5 |        |                  |             |\n",
            "| train_fn_340c8_00015 | PENDING    |                   |           16 |     100 |             8 |      0.00636152 |          25 |           5 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00016 | PENDING    |                   |           64 |     500 |             4 |      0.022412   |          15 |           7 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00017 | PENDING    |                   |           64 |     500 |            32 |      0.021546   |           2 |           5 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00018 | PENDING    |                   |           32 |     150 |             2 |      0.0859522  |          25 |           6 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00019 | PENDING    |                   |           64 |     700 |             1 |      0.0798663  |           1 |           7 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00020 | PENDING    |                   |           64 |    1000 |             4 |      0.033486   |           3 |           5 |           5 |        |                  |             |\n",
            "| train_fn_340c8_00021 | PENDING    |                   |           32 |    1000 |             4 |      0.0194534  |          25 |           3 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00022 | PENDING    |                   |           32 |     100 |            64 |      0.0159701  |          25 |           2 |           4 |        |                  |             |\n",
            "| train_fn_340c8_00000 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0249397  |           2 |           1 |           5 |   1000 |       19.1266    |   0.0939492 |\n",
            "| train_fn_340c8_00001 | TERMINATED | 172.28.0.12:18804 |           32 |    1000 |             1 |      0.00721557 |           5 |           1 |           5 |     64 |        1.16897   |   0.0943291 |\n",
            "| train_fn_340c8_00002 | TERMINATED | 172.28.0.12:18804 |           16 |    1000 |             4 |      0.0382463  |           5 |           2 |           5 |     64 |        1.38149   |   0.100224  |\n",
            "| train_fn_340c8_00003 | TERMINATED | 172.28.0.12:18804 |           32 |      60 |             4 |      0.0624976  |           3 |           3 |           5 |     60 |        1.56004   |   0.0929114 |\n",
            "| train_fn_340c8_00004 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0986488  |           1 |           1 |           2 |      1 |        0.0209789 | 307.631     |\n",
            "| train_fn_340c8_00005 | TERMINATED | 172.28.0.12:18804 |           32 |      80 |             1 |      0.0436456  |          30 |           7 |           3 |      4 |        0.079879  |   0.164952  |\n",
            "| train_fn_340c8_00006 | TERMINATED | 172.28.0.12:18804 |           32 |     500 |            64 |      0.0182318  |          25 |           7 |           1 |      1 |        0.0291367 |   2.26371   |\n",
            "| train_fn_340c8_00007 | TERMINATED | 172.28.0.12:18804 |           64 |      60 |            16 |      0.0212547  |          15 |           8 |           2 |     60 |        0.915847  |   0.0932016 |\n",
            "| train_fn_340c8_00008 | TERMINATED | 172.28.0.12:18804 |           16 |      80 |             4 |      0.0194434  |          15 |           6 |           2 |      2 |        0.0614126 |   0.177311  |\n",
            "| train_fn_340c8_00009 | TERMINATED | 172.28.0.12:18804 |           64 |      80 |             2 |      0.00587327 |          25 |           1 |           4 |      1 |        0.0246794 |   0.44166   |\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "... 9 more trials not shown (6 PENDING, 3 TERMINATED)\n",
            "\n",
            "\n",
            "Result for train_fn_340c8_00013:\n",
            "  date: 2023-07-09_21-48-01\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.3565151318907738\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.023508787155151367\n",
            "  time_this_iter_s: 0.023508787155151367\n",
            "  time_total_s: 0.023508787155151367\n",
            "  timestamp: 1688939281\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00013\n",
            "  \n",
            "Trial train_fn_340c8_00013 completed.\n",
            "Result for train_fn_340c8_00014:\n",
            "  date: 2023-07-09_21-48-01\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.7463856935501099\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.014490604400634766\n",
            "  time_this_iter_s: 0.014490604400634766\n",
            "  time_total_s: 0.014490604400634766\n",
            "  timestamp: 1688939281\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00014\n",
            "  \n",
            "Trial train_fn_340c8_00014 completed.\n",
            "Result for train_fn_340c8_00015:\n",
            "  date: 2023-07-09_21-48-01\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.029481125995516777\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.03145456314086914\n",
            "  time_this_iter_s: 0.03145456314086914\n",
            "  time_total_s: 0.03145456314086914\n",
            "  timestamp: 1688939281\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00015\n",
            "  \n",
            "Result for train_fn_340c8_00015:\n",
            "  date: 2023-07-09_21-48-02\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.18419943377375603\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.13427495956420898\n",
            "  time_this_iter_s: 0.03016209602355957\n",
            "  time_total_s: 0.13427495956420898\n",
            "  timestamp: 1688939282\n",
            "  training_iteration: 4\n",
            "  trial_id: 340c8_00015\n",
            "  \n",
            "Trial train_fn_340c8_00015 completed.\n",
            "Result for train_fn_340c8_00016:\n",
            "  date: 2023-07-09_21-48-02\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7843636274337769\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.015371561050415039\n",
            "  time_this_iter_s: 0.015371561050415039\n",
            "  time_total_s: 0.015371561050415039\n",
            "  timestamp: 1688939282\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00016\n",
            "  \n",
            "Trial train_fn_340c8_00016 completed.\n",
            "Result for train_fn_340c8_00017:\n",
            "  date: 2023-07-09_21-48-02\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.18492737412452698\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.0233156681060791\n",
            "  time_this_iter_s: 0.0233156681060791\n",
            "  time_total_s: 0.0233156681060791\n",
            "  timestamp: 1688939282\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00017\n",
            "  \n",
            "Result for train_fn_340c8_00017:\n",
            "  date: 2023-07-09_21-48-02\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.23193475604057312\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.10124087333679199\n",
            "  time_this_iter_s: 0.022622108459472656\n",
            "  time_total_s: 0.10124087333679199\n",
            "  timestamp: 1688939282\n",
            "  training_iteration: 4\n",
            "  trial_id: 340c8_00017\n",
            "  \n",
            "Trial train_fn_340c8_00017 completed.\n",
            "Result for train_fn_340c8_00018:\n",
            "  date: 2023-07-09_21-48-02\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.10060294717550278\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.016742706298828125\n",
            "  time_this_iter_s: 0.016742706298828125\n",
            "  time_total_s: 0.016742706298828125\n",
            "  timestamp: 1688939282\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00018\n",
            "  \n",
            "Result for train_fn_340c8_00018:\n",
            "  date: 2023-07-09_21-48-02\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.2653675973415375\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.10187339782714844\n",
            "  time_this_iter_s: 0.025089740753173828\n",
            "  time_total_s: 0.10187339782714844\n",
            "  timestamp: 1688939282\n",
            "  training_iteration: 4\n",
            "  trial_id: 340c8_00018\n",
            "  \n",
            "Trial train_fn_340c8_00018 completed.\n",
            "Result for train_fn_340c8_00019:\n",
            "  date: 2023-07-09_21-48-02\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.11037231236696243\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.013878822326660156\n",
            "  time_this_iter_s: 0.013878822326660156\n",
            "  time_total_s: 0.013878822326660156\n",
            "  timestamp: 1688939282\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00019\n",
            "  \n",
            "Result for train_fn_340c8_00019:\n",
            "  date: 2023-07-09_21-48-02\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.12052471935749054\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.043300628662109375\n",
            "  time_this_iter_s: 0.02942180633544922\n",
            "  time_total_s: 0.043300628662109375\n",
            "  timestamp: 1688939282\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00019\n",
            "  \n",
            "Trial train_fn_340c8_00019 completed.\n",
            "Result for train_fn_340c8_00020:\n",
            "  date: 2023-07-09_21-48-02\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.3002367615699768\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.01200246810913086\n",
            "  time_this_iter_s: 0.01200246810913086\n",
            "  time_total_s: 0.01200246810913086\n",
            "  timestamp: 1688939282\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00020\n",
            "  \n",
            "Trial train_fn_340c8_00020 completed.\n",
            "Result for train_fn_340c8_00021:\n",
            "  date: 2023-07-09_21-48-02\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.10415562987327576\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.021518468856811523\n",
            "  time_this_iter_s: 0.021518468856811523\n",
            "  time_total_s: 0.021518468856811523\n",
            "  timestamp: 1688939282\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00021\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2023-07-09 21:48:06 (running for 00:00:36.55)\n",
            "Using AsyncHyperBand: num_stopped=19\n",
            "Bracket: Iter 512.000: -0.09394926577806473 | Iter 256.000: -0.09394465386867523 | Iter 128.000: -0.05930282175540924 | Iter 64.000: -0.08715713396668434 | Iter 32.000: -0.09500441700220108 | Iter 16.000: -0.10298615135252476 | Iter 8.000: -0.1060930248349905 | Iter 4.000: -0.15543796122074127 | Iter 2.000: -0.10458670556545258 | Iter 1.000: -0.18613174557685852\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs\n",
            "Current best trial: 340c8_00021 with loss=0.026910128071904182 and parameters={'batch_size': 32, 'hidden_size': 4, 'num_layer': 3, 'epoch': 1000, 'learning_rate': 0.019453390933782167, 'ds': <__main__.CustomDataset object at 0x7f6fe8673670>, 'test_ds': <__main__.CustomDataset object at 0x7f6fe8673490>, 'input_size': 832, 'tolerance': 2, 'min_delta': 25}\n",
            "Result logdir: /root/ray_results/train_fn_2023-07-09_21-47-30\n",
            "Number of trials: 38/100 (16 PENDING, 1 RUNNING, 21 TERMINATED)\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "| Trial name           | status     | loc               |   batch_size |   epoch |   hidden_size |   learning_rate |   min_delta |   num_layer |   tolerance |   iter |   total time (s) |        loss |\n",
            "|----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------|\n",
            "| train_fn_340c8_00021 | RUNNING    | 172.28.0.12:18804 |           32 |    1000 |             4 |      0.0194534  |          25 |           3 |           2 |    180 |        3.99127   |   0.0269101 |\n",
            "| train_fn_340c8_00022 | PENDING    |                   |           32 |     100 |            64 |      0.0159701  |          25 |           2 |           4 |        |                  |             |\n",
            "| train_fn_340c8_00023 | PENDING    |                   |           64 |      80 |             2 |      0.0146679  |          10 |           8 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00024 | PENDING    |                   |           16 |     150 |             4 |      0.0752408  |          25 |           8 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00025 | PENDING    |                   |           64 |      80 |           128 |      0.00636581 |           5 |           7 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00026 | PENDING    |                   |           64 |     100 |           256 |      0.00961102 |          30 |           2 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00027 | PENDING    |                   |           32 |     500 |            16 |      0.00503378 |          20 |           7 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00028 | PENDING    |                   |           32 |     100 |             1 |      0.00864621 |           2 |           2 |           5 |        |                  |             |\n",
            "| train_fn_340c8_00029 | PENDING    |                   |           64 |    1000 |            32 |      0.00574987 |           5 |           6 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00030 | PENDING    |                   |           32 |      80 |            64 |      0.033664   |           5 |           2 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00031 | PENDING    |                   |           16 |     500 |           128 |      0.00716747 |          10 |           8 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00000 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0249397  |           2 |           1 |           5 |   1000 |       19.1266    |   0.0939492 |\n",
            "| train_fn_340c8_00001 | TERMINATED | 172.28.0.12:18804 |           32 |    1000 |             1 |      0.00721557 |           5 |           1 |           5 |     64 |        1.16897   |   0.0943291 |\n",
            "| train_fn_340c8_00002 | TERMINATED | 172.28.0.12:18804 |           16 |    1000 |             4 |      0.0382463  |           5 |           2 |           5 |     64 |        1.38149   |   0.100224  |\n",
            "| train_fn_340c8_00003 | TERMINATED | 172.28.0.12:18804 |           32 |      60 |             4 |      0.0624976  |           3 |           3 |           5 |     60 |        1.56004   |   0.0929114 |\n",
            "| train_fn_340c8_00004 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0986488  |           1 |           1 |           2 |      1 |        0.0209789 | 307.631     |\n",
            "| train_fn_340c8_00005 | TERMINATED | 172.28.0.12:18804 |           32 |      80 |             1 |      0.0436456  |          30 |           7 |           3 |      4 |        0.079879  |   0.164952  |\n",
            "| train_fn_340c8_00006 | TERMINATED | 172.28.0.12:18804 |           32 |     500 |            64 |      0.0182318  |          25 |           7 |           1 |      1 |        0.0291367 |   2.26371   |\n",
            "| train_fn_340c8_00007 | TERMINATED | 172.28.0.12:18804 |           64 |      60 |            16 |      0.0212547  |          15 |           8 |           2 |     60 |        0.915847  |   0.0932016 |\n",
            "| train_fn_340c8_00008 | TERMINATED | 172.28.0.12:18804 |           16 |      80 |             4 |      0.0194434  |          15 |           6 |           2 |      2 |        0.0614126 |   0.177311  |\n",
            "| train_fn_340c8_00009 | TERMINATED | 172.28.0.12:18804 |           64 |      80 |             2 |      0.00587327 |          25 |           1 |           4 |      1 |        0.0246794 |   0.44166   |\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "... 18 more trials not shown (6 PENDING, 11 TERMINATED)\n",
            "\n",
            "\n",
            "Result for train_fn_340c8_00021:\n",
            "  date: 2023-07-09_21-48-07\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 237\n",
            "  loss: 0.0271905530244112\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 5.035256624221802\n",
            "  time_this_iter_s: 0.01633143424987793\n",
            "  time_total_s: 5.035256624221802\n",
            "  timestamp: 1688939287\n",
            "  training_iteration: 237\n",
            "  trial_id: 340c8_00021\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2023-07-09 21:48:11 (running for 00:00:41.56)\n",
            "Using AsyncHyperBand: num_stopped=19\n",
            "Bracket: Iter 512.000: -0.09394926577806473 | Iter 256.000: -0.06187822576612234 | Iter 128.000: -0.05930282175540924 | Iter 64.000: -0.08715713396668434 | Iter 32.000: -0.09500441700220108 | Iter 16.000: -0.10298615135252476 | Iter 8.000: -0.1060930248349905 | Iter 4.000: -0.15543796122074127 | Iter 2.000: -0.10458670556545258 | Iter 1.000: -0.18613174557685852\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs\n",
            "Current best trial: 340c8_00021 with loss=0.029859932139515877 and parameters={'batch_size': 32, 'hidden_size': 4, 'num_layer': 3, 'epoch': 1000, 'learning_rate': 0.019453390933782167, 'ds': <__main__.CustomDataset object at 0x7f6fe8655840>, 'test_ds': <__main__.CustomDataset object at 0x7f6fe8673490>, 'input_size': 832, 'tolerance': 2, 'min_delta': 25}\n",
            "Result logdir: /root/ray_results/train_fn_2023-07-09_21-47-30\n",
            "Number of trials: 38/100 (16 PENDING, 1 RUNNING, 21 TERMINATED)\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "| Trial name           | status     | loc               |   batch_size |   epoch |   hidden_size |   learning_rate |   min_delta |   num_layer |   tolerance |   iter |   total time (s) |        loss |\n",
            "|----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------|\n",
            "| train_fn_340c8_00021 | RUNNING    | 172.28.0.12:18804 |           32 |    1000 |             4 |      0.0194534  |          25 |           3 |           2 |    387 |        9.02262   |   0.0298599 |\n",
            "| train_fn_340c8_00022 | PENDING    |                   |           32 |     100 |            64 |      0.0159701  |          25 |           2 |           4 |        |                  |             |\n",
            "| train_fn_340c8_00023 | PENDING    |                   |           64 |      80 |             2 |      0.0146679  |          10 |           8 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00024 | PENDING    |                   |           16 |     150 |             4 |      0.0752408  |          25 |           8 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00025 | PENDING    |                   |           64 |      80 |           128 |      0.00636581 |           5 |           7 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00026 | PENDING    |                   |           64 |     100 |           256 |      0.00961102 |          30 |           2 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00027 | PENDING    |                   |           32 |     500 |            16 |      0.00503378 |          20 |           7 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00028 | PENDING    |                   |           32 |     100 |             1 |      0.00864621 |           2 |           2 |           5 |        |                  |             |\n",
            "| train_fn_340c8_00029 | PENDING    |                   |           64 |    1000 |            32 |      0.00574987 |           5 |           6 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00030 | PENDING    |                   |           32 |      80 |            64 |      0.033664   |           5 |           2 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00031 | PENDING    |                   |           16 |     500 |           128 |      0.00716747 |          10 |           8 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00000 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0249397  |           2 |           1 |           5 |   1000 |       19.1266    |   0.0939492 |\n",
            "| train_fn_340c8_00001 | TERMINATED | 172.28.0.12:18804 |           32 |    1000 |             1 |      0.00721557 |           5 |           1 |           5 |     64 |        1.16897   |   0.0943291 |\n",
            "| train_fn_340c8_00002 | TERMINATED | 172.28.0.12:18804 |           16 |    1000 |             4 |      0.0382463  |           5 |           2 |           5 |     64 |        1.38149   |   0.100224  |\n",
            "| train_fn_340c8_00003 | TERMINATED | 172.28.0.12:18804 |           32 |      60 |             4 |      0.0624976  |           3 |           3 |           5 |     60 |        1.56004   |   0.0929114 |\n",
            "| train_fn_340c8_00004 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0986488  |           1 |           1 |           2 |      1 |        0.0209789 | 307.631     |\n",
            "| train_fn_340c8_00005 | TERMINATED | 172.28.0.12:18804 |           32 |      80 |             1 |      0.0436456  |          30 |           7 |           3 |      4 |        0.079879  |   0.164952  |\n",
            "| train_fn_340c8_00006 | TERMINATED | 172.28.0.12:18804 |           32 |     500 |            64 |      0.0182318  |          25 |           7 |           1 |      1 |        0.0291367 |   2.26371   |\n",
            "| train_fn_340c8_00007 | TERMINATED | 172.28.0.12:18804 |           64 |      60 |            16 |      0.0212547  |          15 |           8 |           2 |     60 |        0.915847  |   0.0932016 |\n",
            "| train_fn_340c8_00008 | TERMINATED | 172.28.0.12:18804 |           16 |      80 |             4 |      0.0194434  |          15 |           6 |           2 |      2 |        0.0614126 |   0.177311  |\n",
            "| train_fn_340c8_00009 | TERMINATED | 172.28.0.12:18804 |           64 |      80 |             2 |      0.00587327 |          25 |           1 |           4 |      1 |        0.0246794 |   0.44166   |\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "... 18 more trials not shown (6 PENDING, 11 TERMINATED)\n",
            "\n",
            "\n",
            "Result for train_fn_340c8_00021:\n",
            "  date: 2023-07-09_21-48-12\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 448\n",
            "  loss: 0.041965872049331665\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 10.044579029083252\n",
            "  time_this_iter_s: 0.014248371124267578\n",
            "  time_total_s: 10.044579029083252\n",
            "  timestamp: 1688939292\n",
            "  training_iteration: 448\n",
            "  trial_id: 340c8_00021\n",
            "  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-09 21:48:16,402\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 0.681 s, which may be a performance bottleneck.\n",
            "2023-07-09 21:48:16,403\tWARNING util.py:315 -- The `process_trial_result` operation took 0.683 s, which may be a performance bottleneck.\n",
            "2023-07-09 21:48:16,405\tWARNING util.py:315 -- Processing trial results took 0.684 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
            "2023-07-09 21:48:16,406\tWARNING util.py:315 -- The `process_trial_result` operation took 0.685 s, which may be a performance bottleneck.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Current time: 2023-07-09 21:48:16 (running for 00:00:46.57)\n",
            "Using AsyncHyperBand: num_stopped=19\n",
            "Bracket: Iter 512.000: -0.0648288894444704 | Iter 256.000: -0.06187822576612234 | Iter 128.000: -0.05930282175540924 | Iter 64.000: -0.08715713396668434 | Iter 32.000: -0.09500441700220108 | Iter 16.000: -0.10298615135252476 | Iter 8.000: -0.1060930248349905 | Iter 4.000: -0.15543796122074127 | Iter 2.000: -0.10458670556545258 | Iter 1.000: -0.18613174557685852\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs\n",
            "Current best trial: 340c8_00021 with loss=0.02847253903746605 and parameters={'batch_size': 32, 'hidden_size': 4, 'num_layer': 3, 'epoch': 1000, 'learning_rate': 0.019453390933782167, 'ds': <__main__.CustomDataset object at 0x7f6fe84b5360>, 'test_ds': <__main__.CustomDataset object at 0x7f6fe85e1480>, 'input_size': 832, 'tolerance': 2, 'min_delta': 25}\n",
            "Result logdir: /root/ray_results/train_fn_2023-07-09_21-47-30\n",
            "Number of trials: 38/100 (16 PENDING, 1 RUNNING, 21 TERMINATED)\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "| Trial name           | status     | loc               |   batch_size |   epoch |   hidden_size |   learning_rate |   min_delta |   num_layer |   tolerance |   iter |   total time (s) |        loss |\n",
            "|----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------|\n",
            "| train_fn_340c8_00021 | RUNNING    | 172.28.0.12:18804 |           32 |    1000 |             4 |      0.0194534  |          25 |           3 |           2 |    586 |       14.0261    |   0.0284725 |\n",
            "| train_fn_340c8_00022 | PENDING    |                   |           32 |     100 |            64 |      0.0159701  |          25 |           2 |           4 |        |                  |             |\n",
            "| train_fn_340c8_00023 | PENDING    |                   |           64 |      80 |             2 |      0.0146679  |          10 |           8 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00024 | PENDING    |                   |           16 |     150 |             4 |      0.0752408  |          25 |           8 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00025 | PENDING    |                   |           64 |      80 |           128 |      0.00636581 |           5 |           7 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00026 | PENDING    |                   |           64 |     100 |           256 |      0.00961102 |          30 |           2 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00027 | PENDING    |                   |           32 |     500 |            16 |      0.00503378 |          20 |           7 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00028 | PENDING    |                   |           32 |     100 |             1 |      0.00864621 |           2 |           2 |           5 |        |                  |             |\n",
            "| train_fn_340c8_00029 | PENDING    |                   |           64 |    1000 |            32 |      0.00574987 |           5 |           6 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00030 | PENDING    |                   |           32 |      80 |            64 |      0.033664   |           5 |           2 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00031 | PENDING    |                   |           16 |     500 |           128 |      0.00716747 |          10 |           8 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00000 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0249397  |           2 |           1 |           5 |   1000 |       19.1266    |   0.0939492 |\n",
            "| train_fn_340c8_00001 | TERMINATED | 172.28.0.12:18804 |           32 |    1000 |             1 |      0.00721557 |           5 |           1 |           5 |     64 |        1.16897   |   0.0943291 |\n",
            "| train_fn_340c8_00002 | TERMINATED | 172.28.0.12:18804 |           16 |    1000 |             4 |      0.0382463  |           5 |           2 |           5 |     64 |        1.38149   |   0.100224  |\n",
            "| train_fn_340c8_00003 | TERMINATED | 172.28.0.12:18804 |           32 |      60 |             4 |      0.0624976  |           3 |           3 |           5 |     60 |        1.56004   |   0.0929114 |\n",
            "| train_fn_340c8_00004 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0986488  |           1 |           1 |           2 |      1 |        0.0209789 | 307.631     |\n",
            "| train_fn_340c8_00005 | TERMINATED | 172.28.0.12:18804 |           32 |      80 |             1 |      0.0436456  |          30 |           7 |           3 |      4 |        0.079879  |   0.164952  |\n",
            "| train_fn_340c8_00006 | TERMINATED | 172.28.0.12:18804 |           32 |     500 |            64 |      0.0182318  |          25 |           7 |           1 |      1 |        0.0291367 |   2.26371   |\n",
            "| train_fn_340c8_00007 | TERMINATED | 172.28.0.12:18804 |           64 |      60 |            16 |      0.0212547  |          15 |           8 |           2 |     60 |        0.915847  |   0.0932016 |\n",
            "| train_fn_340c8_00008 | TERMINATED | 172.28.0.12:18804 |           16 |      80 |             4 |      0.0194434  |          15 |           6 |           2 |      2 |        0.0614126 |   0.177311  |\n",
            "| train_fn_340c8_00009 | TERMINATED | 172.28.0.12:18804 |           64 |      80 |             2 |      0.00587327 |          25 |           1 |           4 |      1 |        0.0246794 |   0.44166   |\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "... 18 more trials not shown (6 PENDING, 11 TERMINATED)\n",
            "\n",
            "\n",
            "Result for train_fn_340c8_00021:\n",
            "  date: 2023-07-09_21-48-17\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 630\n",
            "  loss: 0.04170718789100647\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 15.060888290405273\n",
            "  time_this_iter_s: 0.020696163177490234\n",
            "  time_total_s: 15.060888290405273\n",
            "  timestamp: 1688939297\n",
            "  training_iteration: 630\n",
            "  trial_id: 340c8_00021\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2023-07-09 21:48:21 (running for 00:00:51.57)\n",
            "Using AsyncHyperBand: num_stopped=19\n",
            "Bracket: Iter 512.000: -0.0648288894444704 | Iter 256.000: -0.06187822576612234 | Iter 128.000: -0.05930282175540924 | Iter 64.000: -0.08715713396668434 | Iter 32.000: -0.09500441700220108 | Iter 16.000: -0.10298615135252476 | Iter 8.000: -0.1060930248349905 | Iter 4.000: -0.15543796122074127 | Iter 2.000: -0.10458670556545258 | Iter 1.000: -0.18613174557685852\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs\n",
            "Current best trial: 340c8_00021 with loss=0.04099240526556969 and parameters={'batch_size': 32, 'hidden_size': 4, 'num_layer': 3, 'epoch': 1000, 'learning_rate': 0.019453390933782167, 'ds': <__main__.CustomDataset object at 0x7f6fe85e1480>, 'test_ds': <__main__.CustomDataset object at 0x7f6fe84d1f00>, 'input_size': 832, 'tolerance': 2, 'min_delta': 25}\n",
            "Result logdir: /root/ray_results/train_fn_2023-07-09_21-47-30\n",
            "Number of trials: 38/100 (16 PENDING, 1 RUNNING, 21 TERMINATED)\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "| Trial name           | status     | loc               |   batch_size |   epoch |   hidden_size |   learning_rate |   min_delta |   num_layer |   tolerance |   iter |   total time (s) |        loss |\n",
            "|----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------|\n",
            "| train_fn_340c8_00021 | RUNNING    | 172.28.0.12:18804 |           32 |    1000 |             4 |      0.0194534  |          25 |           3 |           2 |    800 |       19.0247    |   0.0409924 |\n",
            "| train_fn_340c8_00022 | PENDING    |                   |           32 |     100 |            64 |      0.0159701  |          25 |           2 |           4 |        |                  |             |\n",
            "| train_fn_340c8_00023 | PENDING    |                   |           64 |      80 |             2 |      0.0146679  |          10 |           8 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00024 | PENDING    |                   |           16 |     150 |             4 |      0.0752408  |          25 |           8 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00025 | PENDING    |                   |           64 |      80 |           128 |      0.00636581 |           5 |           7 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00026 | PENDING    |                   |           64 |     100 |           256 |      0.00961102 |          30 |           2 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00027 | PENDING    |                   |           32 |     500 |            16 |      0.00503378 |          20 |           7 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00028 | PENDING    |                   |           32 |     100 |             1 |      0.00864621 |           2 |           2 |           5 |        |                  |             |\n",
            "| train_fn_340c8_00029 | PENDING    |                   |           64 |    1000 |            32 |      0.00574987 |           5 |           6 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00030 | PENDING    |                   |           32 |      80 |            64 |      0.033664   |           5 |           2 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00031 | PENDING    |                   |           16 |     500 |           128 |      0.00716747 |          10 |           8 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00000 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0249397  |           2 |           1 |           5 |   1000 |       19.1266    |   0.0939492 |\n",
            "| train_fn_340c8_00001 | TERMINATED | 172.28.0.12:18804 |           32 |    1000 |             1 |      0.00721557 |           5 |           1 |           5 |     64 |        1.16897   |   0.0943291 |\n",
            "| train_fn_340c8_00002 | TERMINATED | 172.28.0.12:18804 |           16 |    1000 |             4 |      0.0382463  |           5 |           2 |           5 |     64 |        1.38149   |   0.100224  |\n",
            "| train_fn_340c8_00003 | TERMINATED | 172.28.0.12:18804 |           32 |      60 |             4 |      0.0624976  |           3 |           3 |           5 |     60 |        1.56004   |   0.0929114 |\n",
            "| train_fn_340c8_00004 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0986488  |           1 |           1 |           2 |      1 |        0.0209789 | 307.631     |\n",
            "| train_fn_340c8_00005 | TERMINATED | 172.28.0.12:18804 |           32 |      80 |             1 |      0.0436456  |          30 |           7 |           3 |      4 |        0.079879  |   0.164952  |\n",
            "| train_fn_340c8_00006 | TERMINATED | 172.28.0.12:18804 |           32 |     500 |            64 |      0.0182318  |          25 |           7 |           1 |      1 |        0.0291367 |   2.26371   |\n",
            "| train_fn_340c8_00007 | TERMINATED | 172.28.0.12:18804 |           64 |      60 |            16 |      0.0212547  |          15 |           8 |           2 |     60 |        0.915847  |   0.0932016 |\n",
            "| train_fn_340c8_00008 | TERMINATED | 172.28.0.12:18804 |           16 |      80 |             4 |      0.0194434  |          15 |           6 |           2 |      2 |        0.0614126 |   0.177311  |\n",
            "| train_fn_340c8_00009 | TERMINATED | 172.28.0.12:18804 |           64 |      80 |             2 |      0.00587327 |          25 |           1 |           4 |      1 |        0.0246794 |   0.44166   |\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "... 18 more trials not shown (6 PENDING, 11 TERMINATED)\n",
            "\n",
            "\n",
            "Result for train_fn_340c8_00021:\n",
            "  date: 2023-07-09_21-48-22\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 848\n",
            "  loss: 0.04122493788599968\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 20.06593608856201\n",
            "  time_this_iter_s: 0.03540325164794922\n",
            "  time_total_s: 20.06593608856201\n",
            "  timestamp: 1688939302\n",
            "  training_iteration: 848\n",
            "  trial_id: 340c8_00021\n",
            "  \n",
            "Result for train_fn_340c8_00021:\n",
            "  date: 2023-07-09_21-48-25\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1000\n",
            "  loss: 0.043258946388959885\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 22.769545078277588\n",
            "  time_this_iter_s: 0.01821303367614746\n",
            "  time_total_s: 22.769545078277588\n",
            "  timestamp: 1688939305\n",
            "  training_iteration: 1000\n",
            "  trial_id: 340c8_00021\n",
            "  \n",
            "Trial train_fn_340c8_00021 completed.\n",
            "Result for train_fn_340c8_00022:\n",
            "  date: 2023-07-09_21-48-25\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.19468115270137787\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.0244596004486084\n",
            "  time_this_iter_s: 0.0244596004486084\n",
            "  time_total_s: 0.0244596004486084\n",
            "  timestamp: 1688939305\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00022\n",
            "  \n",
            "Trial train_fn_340c8_00022 completed.\n",
            "Result for train_fn_340c8_00023:\n",
            "  date: 2023-07-09_21-48-25\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.491732656955719\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.01655888557434082\n",
            "  time_this_iter_s: 0.01655888557434082\n",
            "  time_total_s: 0.01655888557434082\n",
            "  timestamp: 1688939305\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00023\n",
            "  \n",
            "Trial train_fn_340c8_00023 completed.\n",
            "Result for train_fn_340c8_00024:\n",
            "  date: 2023-07-09_21-48-25\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.11464010551571846\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.03515291213989258\n",
            "  time_this_iter_s: 0.03515291213989258\n",
            "  time_total_s: 0.03515291213989258\n",
            "  timestamp: 1688939305\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00024\n",
            "  \n",
            "Result for train_fn_340c8_00024:\n",
            "  date: 2023-07-09_21-48-25\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 8\n",
            "  loss: 0.11168376728892326\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.22104787826538086\n",
            "  time_this_iter_s: 0.023895978927612305\n",
            "  time_total_s: 0.22104787826538086\n",
            "  timestamp: 1688939305\n",
            "  training_iteration: 8\n",
            "  trial_id: 340c8_00024\n",
            "  \n",
            "Trial train_fn_340c8_00024 completed.\n",
            "Result for train_fn_340c8_00025:\n",
            "  date: 2023-07-09_21-48-26\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.08777686208486557\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.0324552059173584\n",
            "  time_this_iter_s: 0.0324552059173584\n",
            "  time_total_s: 0.0324552059173584\n",
            "  timestamp: 1688939306\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00025\n",
            "  \n",
            "Result for train_fn_340c8_00025:\n",
            "  date: 2023-07-09_21-48-26\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.10802233964204788\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.05830097198486328\n",
            "  time_this_iter_s: 0.025845766067504883\n",
            "  time_total_s: 0.05830097198486328\n",
            "  timestamp: 1688939306\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00025\n",
            "  \n",
            "Trial train_fn_340c8_00025 completed.\n",
            "Result for train_fn_340c8_00026:\n",
            "  date: 2023-07-09_21-48-26\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 14.061939239501953\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.024182558059692383\n",
            "  time_this_iter_s: 0.024182558059692383\n",
            "  time_total_s: 0.024182558059692383\n",
            "  timestamp: 1688939306\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00026\n",
            "  \n",
            "Trial train_fn_340c8_00026 completed.\n",
            "Result for train_fn_340c8_00027:\n",
            "  date: 2023-07-09_21-48-26\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.29316389560699463\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.014329195022583008\n",
            "  time_this_iter_s: 0.014329195022583008\n",
            "  time_total_s: 0.014329195022583008\n",
            "  timestamp: 1688939306\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00027\n",
            "  \n",
            "Trial train_fn_340c8_00027 completed.\n",
            "Result for train_fn_340c8_00028:\n",
            "  date: 2023-07-09_21-48-26\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.0695880725979805\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.01589345932006836\n",
            "  time_this_iter_s: 0.01589345932006836\n",
            "  time_total_s: 0.01589345932006836\n",
            "  timestamp: 1688939306\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00028\n",
            "  \n",
            "Result for train_fn_340c8_00028:\n",
            "  date: 2023-07-09_21-48-26\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 32\n",
            "  loss: 0.09529682248830795\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.519615888595581\n",
            "  time_this_iter_s: 0.013952016830444336\n",
            "  time_total_s: 0.519615888595581\n",
            "  timestamp: 1688939306\n",
            "  training_iteration: 32\n",
            "  trial_id: 340c8_00028\n",
            "  \n",
            "Trial train_fn_340c8_00028 completed.\n",
            "Result for train_fn_340c8_00029:\n",
            "  date: 2023-07-09_21-48-26\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.15144450962543488\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.013778448104858398\n",
            "  time_this_iter_s: 0.013778448104858398\n",
            "  time_total_s: 0.013778448104858398\n",
            "  timestamp: 1688939306\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00029\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2023-07-09 21:48:26 (running for 00:00:56.57)\n",
            "Using AsyncHyperBand: num_stopped=27\n",
            "Bracket: Iter 512.000: -0.0648288894444704 | Iter 256.000: -0.06187822576612234 | Iter 128.000: -0.05930282175540924 | Iter 64.000: -0.08715713396668434 | Iter 32.000: -0.09515061974525452 | Iter 16.000: -0.09967902023345232 | Iter 8.000: -0.1060930248349905 | Iter 4.000: -0.13681656494736671 | Iter 2.000: -0.08864869177341461 | Iter 1.000: -0.18613174557685852\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs\n",
            "Current best trial: 340c8_00021 with loss=0.043258946388959885 and parameters={'batch_size': 32, 'hidden_size': 4, 'num_layer': 3, 'epoch': 1000, 'learning_rate': 0.019453390933782167, 'ds': <__main__.CustomDataset object at 0x7f6fe84d28c0>, 'test_ds': <__main__.CustomDataset object at 0x7f6fe84b5360>, 'input_size': 832, 'tolerance': 2, 'min_delta': 25}\n",
            "Result logdir: /root/ray_results/train_fn_2023-07-09_21-47-30\n",
            "Number of trials: 46/100 (16 PENDING, 1 RUNNING, 29 TERMINATED)\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "| Trial name           | status     | loc               |   batch_size |   epoch |   hidden_size |   learning_rate |   min_delta |   num_layer |   tolerance |   iter |   total time (s) |        loss |\n",
            "|----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------|\n",
            "| train_fn_340c8_00029 | RUNNING    | 172.28.0.12:18804 |           64 |    1000 |            32 |      0.00574987 |           5 |           6 |           1 |      1 |        0.0137784 |   0.151445  |\n",
            "| train_fn_340c8_00030 | PENDING    |                   |           32 |      80 |            64 |      0.033664   |           5 |           2 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00031 | PENDING    |                   |           16 |     500 |           128 |      0.00716747 |          10 |           8 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00032 | PENDING    |                   |           16 |     200 |             8 |      0.00708865 |          25 |           2 |           4 |        |                  |             |\n",
            "| train_fn_340c8_00033 | PENDING    |                   |           16 |     200 |            32 |      0.0643573  |          15 |           5 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00034 | PENDING    |                   |           32 |     500 |            16 |      0.0628009  |           3 |           1 |           5 |        |                  |             |\n",
            "| train_fn_340c8_00035 | PENDING    |                   |           16 |      80 |            64 |      0.00558762 |          30 |           3 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00036 | PENDING    |                   |           64 |      60 |           256 |      0.0956341  |           2 |           1 |           5 |        |                  |             |\n",
            "| train_fn_340c8_00037 | PENDING    |                   |           32 |     500 |            16 |      0.00803276 |           3 |           5 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00038 | PENDING    |                   |           16 |     700 |            32 |      0.0262573  |          20 |           6 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00039 | PENDING    |                   |           32 |      80 |           256 |      0.0572701  |          20 |           6 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00000 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0249397  |           2 |           1 |           5 |   1000 |       19.1266    |   0.0939492 |\n",
            "| train_fn_340c8_00001 | TERMINATED | 172.28.0.12:18804 |           32 |    1000 |             1 |      0.00721557 |           5 |           1 |           5 |     64 |        1.16897   |   0.0943291 |\n",
            "| train_fn_340c8_00002 | TERMINATED | 172.28.0.12:18804 |           16 |    1000 |             4 |      0.0382463  |           5 |           2 |           5 |     64 |        1.38149   |   0.100224  |\n",
            "| train_fn_340c8_00003 | TERMINATED | 172.28.0.12:18804 |           32 |      60 |             4 |      0.0624976  |           3 |           3 |           5 |     60 |        1.56004   |   0.0929114 |\n",
            "| train_fn_340c8_00004 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0986488  |           1 |           1 |           2 |      1 |        0.0209789 | 307.631     |\n",
            "| train_fn_340c8_00005 | TERMINATED | 172.28.0.12:18804 |           32 |      80 |             1 |      0.0436456  |          30 |           7 |           3 |      4 |        0.079879  |   0.164952  |\n",
            "| train_fn_340c8_00006 | TERMINATED | 172.28.0.12:18804 |           32 |     500 |            64 |      0.0182318  |          25 |           7 |           1 |      1 |        0.0291367 |   2.26371   |\n",
            "| train_fn_340c8_00007 | TERMINATED | 172.28.0.12:18804 |           64 |      60 |            16 |      0.0212547  |          15 |           8 |           2 |     60 |        0.915847  |   0.0932016 |\n",
            "| train_fn_340c8_00008 | TERMINATED | 172.28.0.12:18804 |           16 |      80 |             4 |      0.0194434  |          15 |           6 |           2 |      2 |        0.0614126 |   0.177311  |\n",
            "| train_fn_340c8_00009 | TERMINATED | 172.28.0.12:18804 |           64 |      80 |             2 |      0.00587327 |          25 |           1 |           4 |      1 |        0.0246794 |   0.44166   |\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "... 26 more trials not shown (6 PENDING, 19 TERMINATED)\n",
            "\n",
            "\n",
            "Result for train_fn_340c8_00029:\n",
            "  date: 2023-07-09_21-48-26\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.10183195769786835\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.035698890686035156\n",
            "  time_this_iter_s: 0.021920442581176758\n",
            "  time_total_s: 0.035698890686035156\n",
            "  timestamp: 1688939306\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00029\n",
            "  \n",
            "Trial train_fn_340c8_00029 completed.\n",
            "Result for train_fn_340c8_00030:\n",
            "  date: 2023-07-09_21-48-26\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.07324255257844925\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.015492916107177734\n",
            "  time_this_iter_s: 0.015492916107177734\n",
            "  time_total_s: 0.015492916107177734\n",
            "  timestamp: 1688939306\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00030\n",
            "  \n",
            "Result for train_fn_340c8_00030:\n",
            "  date: 2023-07-09_21-48-27\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 64\n",
            "  loss: 0.09346862137317657\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 1.0818049907684326\n",
            "  time_this_iter_s: 0.016161441802978516\n",
            "  time_total_s: 1.0818049907684326\n",
            "  timestamp: 1688939307\n",
            "  training_iteration: 64\n",
            "  trial_id: 340c8_00030\n",
            "  \n",
            "Trial train_fn_340c8_00030 completed.\n",
            "Result for train_fn_340c8_00031:\n",
            "  date: 2023-07-09_21-48-27\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.02981527429074049\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.04491400718688965\n",
            "  time_this_iter_s: 0.04491400718688965\n",
            "  time_total_s: 0.04491400718688965\n",
            "  timestamp: 1688939307\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00031\n",
            "  \n",
            "Result for train_fn_340c8_00031:\n",
            "  date: 2023-07-09_21-48-28\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 16\n",
            "  loss: 0.0996549129486084\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.513031005859375\n",
            "  time_this_iter_s: 0.03145766258239746\n",
            "  time_total_s: 0.513031005859375\n",
            "  timestamp: 1688939308\n",
            "  training_iteration: 16\n",
            "  trial_id: 340c8_00031\n",
            "  \n",
            "Trial train_fn_340c8_00031 completed.\n",
            "Result for train_fn_340c8_00032:\n",
            "  date: 2023-07-09_21-48-28\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.15763797983527184\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.0189363956451416\n",
            "  time_this_iter_s: 0.0189363956451416\n",
            "  time_total_s: 0.0189363956451416\n",
            "  timestamp: 1688939308\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00032\n",
            "  \n",
            "Result for train_fn_340c8_00032:\n",
            "  date: 2023-07-09_21-48-28\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.23439620435237885\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.08658742904663086\n",
            "  time_this_iter_s: 0.02302861213684082\n",
            "  time_total_s: 0.08658742904663086\n",
            "  timestamp: 1688939308\n",
            "  training_iteration: 4\n",
            "  trial_id: 340c8_00032\n",
            "  \n",
            "Trial train_fn_340c8_00032 completed.\n",
            "Result for train_fn_340c8_00033:\n",
            "  date: 2023-07-09_21-48-28\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.1174241304397583\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.024169921875\n",
            "  time_this_iter_s: 0.024169921875\n",
            "  time_total_s: 0.024169921875\n",
            "  timestamp: 1688939308\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00033\n",
            "  \n",
            "Result for train_fn_340c8_00033:\n",
            "  date: 2023-07-09_21-48-31\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 128\n",
            "  loss: 0.09146765992045403\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 2.920440673828125\n",
            "  time_this_iter_s: 0.0234222412109375\n",
            "  time_total_s: 2.920440673828125\n",
            "  timestamp: 1688939311\n",
            "  training_iteration: 128\n",
            "  trial_id: 340c8_00033\n",
            "  \n",
            "Trial train_fn_340c8_00033 completed.\n",
            "Result for train_fn_340c8_00034:\n",
            "  date: 2023-07-09_21-48-31\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.4670884609222412\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.012909173965454102\n",
            "  time_this_iter_s: 0.012909173965454102\n",
            "  time_total_s: 0.012909173965454102\n",
            "  timestamp: 1688939311\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00034\n",
            "  \n",
            "Trial train_fn_340c8_00034 completed.\n",
            "Result for train_fn_340c8_00035:\n",
            "  date: 2023-07-09_21-48-31\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.37786443531513214\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.023256778717041016\n",
            "  time_this_iter_s: 0.023256778717041016\n",
            "  time_total_s: 0.023256778717041016\n",
            "  timestamp: 1688939311\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00035\n",
            "  \n",
            "Trial train_fn_340c8_00035 completed.\n",
            "Result for train_fn_340c8_00036:\n",
            "  date: 2023-07-09_21-48-31\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 260.5765075683594\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.0207827091217041\n",
            "  time_this_iter_s: 0.0207827091217041\n",
            "  time_total_s: 0.0207827091217041\n",
            "  timestamp: 1688939311\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00036\n",
            "  \n",
            "Trial train_fn_340c8_00036 completed.\n",
            "Result for train_fn_340c8_00037:\n",
            "  date: 2023-07-09_21-48-31\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.29576125741004944\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.015950918197631836\n",
            "  time_this_iter_s: 0.015950918197631836\n",
            "  time_total_s: 0.015950918197631836\n",
            "  timestamp: 1688939311\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00037\n",
            "  \n",
            "Trial train_fn_340c8_00037 completed.\n",
            "Result for train_fn_340c8_00038:\n",
            "  date: 2023-07-09_21-48-31\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.029404212720692158\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.02260279655456543\n",
            "  time_this_iter_s: 0.02260279655456543\n",
            "  time_total_s: 0.02260279655456543\n",
            "  timestamp: 1688939311\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00038\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2023-07-09 21:48:31 (running for 00:01:01.60)\n",
            "Using AsyncHyperBand: num_stopped=36\n",
            "Bracket: Iter 512.000: -0.0648288894444704 | Iter 256.000: -0.06187822576612234 | Iter 128.000: -0.09052281826734543 | Iter 64.000: -0.09332925453782082 | Iter 32.000: -0.09473007544875145 | Iter 16.000: -0.09637188911437988 | Iter 8.000: -0.09207047335803509 | Iter 4.000: -0.12567486986517906 | Iter 2.000: -0.07497358415275812 | Iter 1.000: -0.18492737412452698\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs\n",
            "Current best trial: 340c8_00038 with loss=0.029404212720692158 and parameters={'batch_size': 16, 'hidden_size': 32, 'num_layer': 6, 'epoch': 700, 'learning_rate': 0.026257332317187975, 'ds': <__main__.CustomDataset object at 0x7f6fe858e5c0>, 'test_ds': <__main__.CustomDataset object at 0x7f6fe858dc30>, 'input_size': 832, 'tolerance': 3, 'min_delta': 20}\n",
            "Result logdir: /root/ray_results/train_fn_2023-07-09_21-47-30\n",
            "Number of trials: 55/100 (16 PENDING, 1 RUNNING, 38 TERMINATED)\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "| Trial name           | status     | loc               |   batch_size |   epoch |   hidden_size |   learning_rate |   min_delta |   num_layer |   tolerance |   iter |   total time (s) |        loss |\n",
            "|----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------|\n",
            "| train_fn_340c8_00038 | RUNNING    | 172.28.0.12:18804 |           16 |     700 |            32 |      0.0262573  |          20 |           6 |           3 |      1 |        0.0226028 |   0.0294042 |\n",
            "| train_fn_340c8_00039 | PENDING    |                   |           32 |      80 |           256 |      0.0572701  |          20 |           6 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00040 | PENDING    |                   |           16 |     100 |             1 |      0.0277341  |           3 |           1 |           4 |        |                  |             |\n",
            "| train_fn_340c8_00041 | PENDING    |                   |           16 |     700 |           128 |      0.0594896  |          15 |           7 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00042 | PENDING    |                   |           64 |     200 |            16 |      0.0712592  |          10 |           6 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00043 | PENDING    |                   |           32 |     100 |             4 |      0.0181705  |           5 |           2 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00044 | PENDING    |                   |           32 |      80 |            32 |      0.0631437  |           1 |           5 |           5 |        |                  |             |\n",
            "| train_fn_340c8_00045 | PENDING    |                   |           64 |      60 |             2 |      0.00950874 |          25 |           8 |           2 |        |                  |             |\n",
            "| train_fn_340c8_00046 | PENDING    |                   |           64 |     150 |             2 |      0.00887302 |           5 |           2 |           5 |        |                  |             |\n",
            "| train_fn_340c8_00047 | PENDING    |                   |           32 |    1000 |            32 |      0.0353193  |          10 |           8 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00048 | PENDING    |                   |           64 |     500 |             2 |      0.0556438  |          15 |           7 |           5 |        |                  |             |\n",
            "| train_fn_340c8_00000 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0249397  |           2 |           1 |           5 |   1000 |       19.1266    |   0.0939492 |\n",
            "| train_fn_340c8_00001 | TERMINATED | 172.28.0.12:18804 |           32 |    1000 |             1 |      0.00721557 |           5 |           1 |           5 |     64 |        1.16897   |   0.0943291 |\n",
            "| train_fn_340c8_00002 | TERMINATED | 172.28.0.12:18804 |           16 |    1000 |             4 |      0.0382463  |           5 |           2 |           5 |     64 |        1.38149   |   0.100224  |\n",
            "| train_fn_340c8_00003 | TERMINATED | 172.28.0.12:18804 |           32 |      60 |             4 |      0.0624976  |           3 |           3 |           5 |     60 |        1.56004   |   0.0929114 |\n",
            "| train_fn_340c8_00004 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0986488  |           1 |           1 |           2 |      1 |        0.0209789 | 307.631     |\n",
            "| train_fn_340c8_00005 | TERMINATED | 172.28.0.12:18804 |           32 |      80 |             1 |      0.0436456  |          30 |           7 |           3 |      4 |        0.079879  |   0.164952  |\n",
            "| train_fn_340c8_00006 | TERMINATED | 172.28.0.12:18804 |           32 |     500 |            64 |      0.0182318  |          25 |           7 |           1 |      1 |        0.0291367 |   2.26371   |\n",
            "| train_fn_340c8_00007 | TERMINATED | 172.28.0.12:18804 |           64 |      60 |            16 |      0.0212547  |          15 |           8 |           2 |     60 |        0.915847  |   0.0932016 |\n",
            "| train_fn_340c8_00008 | TERMINATED | 172.28.0.12:18804 |           16 |      80 |             4 |      0.0194434  |          15 |           6 |           2 |      2 |        0.0614126 |   0.177311  |\n",
            "| train_fn_340c8_00009 | TERMINATED | 172.28.0.12:18804 |           64 |      80 |             2 |      0.00587327 |          25 |           1 |           4 |      1 |        0.0246794 |   0.44166   |\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "... 35 more trials not shown (6 PENDING, 28 TERMINATED)\n",
            "\n",
            "\n",
            "Result for train_fn_340c8_00038:\n",
            "  date: 2023-07-09_21-48-32\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 8\n",
            "  loss: 0.11642863415181637\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.26239490509033203\n",
            "  time_this_iter_s: 0.022742509841918945\n",
            "  time_total_s: 0.26239490509033203\n",
            "  timestamp: 1688939312\n",
            "  training_iteration: 8\n",
            "  trial_id: 340c8_00038\n",
            "  \n",
            "Trial train_fn_340c8_00038 completed.\n",
            "Result for train_fn_340c8_00039:\n",
            "  date: 2023-07-09_21-48-32\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 23.589487075805664\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.05259537696838379\n",
            "  time_this_iter_s: 0.05259537696838379\n",
            "  time_total_s: 0.05259537696838379\n",
            "  timestamp: 1688939312\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00039\n",
            "  \n",
            "Trial train_fn_340c8_00039 completed.\n",
            "Result for train_fn_340c8_00040:\n",
            "  date: 2023-07-09_21-48-32\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.05529547855257988\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.01851677894592285\n",
            "  time_this_iter_s: 0.01851677894592285\n",
            "  time_total_s: 0.01851677894592285\n",
            "  timestamp: 1688939312\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00040\n",
            "  \n",
            "Result for train_fn_340c8_00040:\n",
            "  date: 2023-07-09_21-48-32\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 8\n",
            "  loss: 0.14445451647043228\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.1748828887939453\n",
            "  time_this_iter_s: 0.019947290420532227\n",
            "  time_total_s: 0.1748828887939453\n",
            "  timestamp: 1688939312\n",
            "  training_iteration: 8\n",
            "  trial_id: 340c8_00040\n",
            "  \n",
            "Trial train_fn_340c8_00040 completed.\n",
            "Result for train_fn_340c8_00041:\n",
            "  date: 2023-07-09_21-48-32\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 2.6992924213409424\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.05448651313781738\n",
            "  time_this_iter_s: 0.05448651313781738\n",
            "  time_total_s: 0.05448651313781738\n",
            "  timestamp: 1688939312\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00041\n",
            "  \n",
            "Trial train_fn_340c8_00041 completed.\n",
            "Result for train_fn_340c8_00042:\n",
            "  date: 2023-07-09_21-48-32\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.16103003919124603\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.01340174674987793\n",
            "  time_this_iter_s: 0.01340174674987793\n",
            "  time_total_s: 0.01340174674987793\n",
            "  timestamp: 1688939312\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00042\n",
            "  \n",
            "Result for train_fn_340c8_00042:\n",
            "  date: 2023-07-09_21-48-32\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.1692565530538559\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.09155154228210449\n",
            "  time_this_iter_s: 0.021809816360473633\n",
            "  time_total_s: 0.09155154228210449\n",
            "  timestamp: 1688939312\n",
            "  training_iteration: 4\n",
            "  trial_id: 340c8_00042\n",
            "  \n",
            "Trial train_fn_340c8_00042 completed.\n",
            "Result for train_fn_340c8_00043:\n",
            "  date: 2023-07-09_21-48-32\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.3746461570262909\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.01262974739074707\n",
            "  time_this_iter_s: 0.01262974739074707\n",
            "  time_total_s: 0.01262974739074707\n",
            "  timestamp: 1688939312\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00043\n",
            "  \n",
            "Trial train_fn_340c8_00043 completed.\n",
            "Result for train_fn_340c8_00044:\n",
            "  date: 2023-07-09_21-48-32\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.08558342605829239\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.026813268661499023\n",
            "  time_this_iter_s: 0.026813268661499023\n",
            "  time_total_s: 0.026813268661499023\n",
            "  timestamp: 1688939312\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00044\n",
            "  \n",
            "Result for train_fn_340c8_00044:\n",
            "  date: 2023-07-09_21-48-32\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.22092989087104797\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.07470989227294922\n",
            "  time_this_iter_s: 0.047896623611450195\n",
            "  time_total_s: 0.07470989227294922\n",
            "  timestamp: 1688939312\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00044\n",
            "  \n",
            "Trial train_fn_340c8_00044 completed.\n",
            "Result for train_fn_340c8_00045:\n",
            "  date: 2023-07-09_21-48-32\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.29137754440307617\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.013482809066772461\n",
            "  time_this_iter_s: 0.013482809066772461\n",
            "  time_total_s: 0.013482809066772461\n",
            "  timestamp: 1688939312\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00045\n",
            "  \n",
            "Trial train_fn_340c8_00045 completed.\n",
            "Result for train_fn_340c8_00046:\n",
            "  date: 2023-07-09_21-48-32\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.03194453939795494\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.010826587677001953\n",
            "  time_this_iter_s: 0.010826587677001953\n",
            "  time_total_s: 0.010826587677001953\n",
            "  timestamp: 1688939312\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00046\n",
            "  \n",
            "Result for train_fn_340c8_00046:\n",
            "  date: 2023-07-09_21-48-33\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 32\n",
            "  loss: 0.11772016435861588\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.922661304473877\n",
            "  time_this_iter_s: 0.01897907257080078\n",
            "  time_total_s: 0.922661304473877\n",
            "  timestamp: 1688939313\n",
            "  training_iteration: 32\n",
            "  trial_id: 340c8_00046\n",
            "  \n",
            "Trial train_fn_340c8_00046 completed.\n",
            "Result for train_fn_340c8_00047:\n",
            "  date: 2023-07-09_21-48-33\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.07412761449813843\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.020281076431274414\n",
            "  time_this_iter_s: 0.020281076431274414\n",
            "  time_total_s: 0.020281076431274414\n",
            "  timestamp: 1688939313\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00047\n",
            "  \n",
            "Result for train_fn_340c8_00047:\n",
            "  date: 2023-07-09_21-48-34\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 8\n",
            "  loss: 0.11058774590492249\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.2161414623260498\n",
            "  time_this_iter_s: 0.02337932586669922\n",
            "  time_total_s: 0.2161414623260498\n",
            "  timestamp: 1688939314\n",
            "  training_iteration: 8\n",
            "  trial_id: 340c8_00047\n",
            "  \n",
            "Trial train_fn_340c8_00047 completed.\n",
            "Result for train_fn_340c8_00048:\n",
            "  date: 2023-07-09_21-48-34\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.07001714408397675\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.014100074768066406\n",
            "  time_this_iter_s: 0.014100074768066406\n",
            "  time_total_s: 0.014100074768066406\n",
            "  timestamp: 1688939314\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00048\n",
            "  \n",
            "Result for train_fn_340c8_00048:\n",
            "  date: 2023-07-09_21-48-34\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.1490316092967987\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.07902026176452637\n",
            "  time_this_iter_s: 0.02266073226928711\n",
            "  time_total_s: 0.07902026176452637\n",
            "  timestamp: 1688939314\n",
            "  training_iteration: 4\n",
            "  trial_id: 340c8_00048\n",
            "  \n",
            "Trial train_fn_340c8_00048 completed.\n",
            "Result for train_fn_340c8_00049:\n",
            "  date: 2023-07-09_21-48-34\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.08992613106966019\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.021950721740722656\n",
            "  time_this_iter_s: 0.021950721740722656\n",
            "  time_total_s: 0.021950721740722656\n",
            "  timestamp: 1688939314\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00049\n",
            "  \n",
            "Result for train_fn_340c8_00049:\n",
            "  date: 2023-07-09_21-48-34\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.14735212922096252\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.08895730972290039\n",
            "  time_this_iter_s: 0.020952939987182617\n",
            "  time_total_s: 0.08895730972290039\n",
            "  timestamp: 1688939314\n",
            "  training_iteration: 4\n",
            "  trial_id: 340c8_00049\n",
            "  \n",
            "Trial train_fn_340c8_00049 completed.\n",
            "Result for train_fn_340c8_00050:\n",
            "  date: 2023-07-09_21-48-34\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.2345850467681885\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.009386777877807617\n",
            "  time_this_iter_s: 0.009386777877807617\n",
            "  time_total_s: 0.009386777877807617\n",
            "  timestamp: 1688939314\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00050\n",
            "  \n",
            "Trial train_fn_340c8_00050 completed.\n",
            "Result for train_fn_340c8_00051:\n",
            "  date: 2023-07-09_21-48-34\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.480913370847702\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.008777379989624023\n",
            "  time_this_iter_s: 0.008777379989624023\n",
            "  time_total_s: 0.008777379989624023\n",
            "  timestamp: 1688939314\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00051\n",
            "  \n",
            "Trial train_fn_340c8_00051 completed.\n",
            "Result for train_fn_340c8_00052:\n",
            "  date: 2023-07-09_21-48-34\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 2.570521593093872\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.09092307090759277\n",
            "  time_this_iter_s: 0.09092307090759277\n",
            "  time_total_s: 0.09092307090759277\n",
            "  timestamp: 1688939314\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00052\n",
            "  \n",
            "Trial train_fn_340c8_00052 completed.\n",
            "Result for train_fn_340c8_00053:\n",
            "  date: 2023-07-09_21-48-34\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.07492059841752052\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.026317834854125977\n",
            "  time_this_iter_s: 0.026317834854125977\n",
            "  time_total_s: 0.026317834854125977\n",
            "  timestamp: 1688939314\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00053\n",
            "  \n",
            "Result for train_fn_340c8_00053:\n",
            "  date: 2023-07-09_21-48-34\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.12083844095468521\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.0813899040222168\n",
            "  time_this_iter_s: 0.05507206916809082\n",
            "  time_total_s: 0.0813899040222168\n",
            "  timestamp: 1688939314\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00053\n",
            "  \n",
            "Trial train_fn_340c8_00053 completed.\n",
            "Result for train_fn_340c8_00054:\n",
            "  date: 2023-07-09_21-48-34\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.10684140026569366\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.04079627990722656\n",
            "  time_this_iter_s: 0.04079627990722656\n",
            "  time_total_s: 0.04079627990722656\n",
            "  timestamp: 1688939314\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00054\n",
            "  \n",
            "Result for train_fn_340c8_00054:\n",
            "  date: 2023-07-09_21-48-35\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 32\n",
            "  loss: 0.09603136777877808\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.8469448089599609\n",
            "  time_this_iter_s: 0.028714656829833984\n",
            "  time_total_s: 0.8469448089599609\n",
            "  timestamp: 1688939315\n",
            "  training_iteration: 32\n",
            "  trial_id: 340c8_00054\n",
            "  \n",
            "Trial train_fn_340c8_00054 completed.\n",
            "Result for train_fn_340c8_00055:\n",
            "  date: 2023-07-09_21-48-35\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.256824254989624\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.034371376037597656\n",
            "  time_this_iter_s: 0.034371376037597656\n",
            "  time_total_s: 0.034371376037597656\n",
            "  timestamp: 1688939315\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00055\n",
            "  \n",
            "Trial train_fn_340c8_00055 completed.\n",
            "Result for train_fn_340c8_00056:\n",
            "  date: 2023-07-09_21-48-35\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.06008295342326164\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.02325582504272461\n",
            "  time_this_iter_s: 0.02325582504272461\n",
            "  time_total_s: 0.02325582504272461\n",
            "  timestamp: 1688939315\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00056\n",
            "  \n",
            "Result for train_fn_340c8_00056:\n",
            "  date: 2023-07-09_21-48-36\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.2633337676525116\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.06432032585144043\n",
            "  time_this_iter_s: 0.04106450080871582\n",
            "  time_total_s: 0.06432032585144043\n",
            "  timestamp: 1688939316\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00056\n",
            "  \n",
            "Trial train_fn_340c8_00056 completed.\n",
            "Result for train_fn_340c8_00057:\n",
            "  date: 2023-07-09_21-48-36\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9702215194702148\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.03743457794189453\n",
            "  time_this_iter_s: 0.03743457794189453\n",
            "  time_total_s: 0.03743457794189453\n",
            "  timestamp: 1688939316\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00057\n",
            "  \n",
            "Trial train_fn_340c8_00057 completed.\n",
            "Result for train_fn_340c8_00058:\n",
            "  date: 2023-07-09_21-48-36\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.130196362733841\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.026404380798339844\n",
            "  time_this_iter_s: 0.026404380798339844\n",
            "  time_total_s: 0.026404380798339844\n",
            "  timestamp: 1688939316\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00058\n",
            "  \n",
            "Trial train_fn_340c8_00058 completed.\n",
            "Result for train_fn_340c8_00059:\n",
            "  date: 2023-07-09_21-48-36\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.030348002910614014\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.015130043029785156\n",
            "  time_this_iter_s: 0.015130043029785156\n",
            "  time_total_s: 0.015130043029785156\n",
            "  timestamp: 1688939316\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00059\n",
            "  \n",
            "Result for train_fn_340c8_00059:\n",
            "  date: 2023-07-09_21-48-36\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 16\n",
            "  loss: 0.11173566430807114\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.37293481826782227\n",
            "  time_this_iter_s: 0.020760536193847656\n",
            "  time_total_s: 0.37293481826782227\n",
            "  timestamp: 1688939316\n",
            "  training_iteration: 16\n",
            "  trial_id: 340c8_00059\n",
            "  \n",
            "Trial train_fn_340c8_00059 completed.\n",
            "Result for train_fn_340c8_00060:\n",
            "  date: 2023-07-09_21-48-36\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.08228099346160889\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.02184748649597168\n",
            "  time_this_iter_s: 0.02184748649597168\n",
            "  time_total_s: 0.02184748649597168\n",
            "  timestamp: 1688939316\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00060\n",
            "  \n",
            "Result for train_fn_340c8_00060:\n",
            "  date: 2023-07-09_21-48-36\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.1650378182530403\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.11147832870483398\n",
            "  time_this_iter_s: 0.02729654312133789\n",
            "  time_total_s: 0.11147832870483398\n",
            "  timestamp: 1688939316\n",
            "  training_iteration: 4\n",
            "  trial_id: 340c8_00060\n",
            "  \n",
            "Trial train_fn_340c8_00060 completed.\n",
            "== Status ==\n",
            "Current time: 2023-07-09 21:48:36 (running for 00:01:06.63)\n",
            "Using AsyncHyperBand: num_stopped=59\n",
            "Bracket: Iter 512.000: -0.0648288894444704 | Iter 256.000: -0.06187822576612234 | Iter 128.000: -0.09052281826734543 | Iter 64.000: -0.09332925453782082 | Iter 32.000: -0.09515061974525452 | Iter 16.000: -0.09534086287021637 | Iter 8.000: -0.09207047335803509 | Iter 4.000: -0.11281711421906948 | Iter 2.000: -0.05413432419300079 | Iter 1.000: -0.16103003919124603\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs\n",
            "Current best trial: 340c8_00021 with loss=0.043258946388959885 and parameters={'batch_size': 32, 'hidden_size': 4, 'num_layer': 3, 'epoch': 1000, 'learning_rate': 0.019453390933782167, 'ds': <__main__.CustomDataset object at 0x7f6fe84d28c0>, 'test_ds': <__main__.CustomDataset object at 0x7f6fe84b5360>, 'input_size': 832, 'tolerance': 2, 'min_delta': 25}\n",
            "Result logdir: /root/ray_results/train_fn_2023-07-09_21-47-30\n",
            "Number of trials: 77/100 (16 PENDING, 61 TERMINATED)\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "| Trial name           | status     | loc               |   batch_size |   epoch |   hidden_size |   learning_rate |   min_delta |   num_layer |   tolerance |   iter |   total time (s) |        loss |\n",
            "|----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------|\n",
            "| train_fn_340c8_00061 | PENDING    |                   |           32 |      60 |           128 |      0.00704577 |          30 |           5 |           5 |        |                  |             |\n",
            "| train_fn_340c8_00062 | PENDING    |                   |           32 |     150 |             4 |      0.00621334 |           1 |           5 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00063 | PENDING    |                   |           64 |     500 |           256 |      0.0709445  |           5 |           6 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00064 | PENDING    |                   |           16 |     150 |             8 |      0.0052856  |          15 |           7 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00065 | PENDING    |                   |           16 |      80 |             4 |      0.0114692  |          20 |           1 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00066 | PENDING    |                   |           64 |    1000 |            32 |      0.0981438  |           3 |           6 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00067 | PENDING    |                   |           16 |     500 |           256 |      0.0409379  |           1 |           6 |           5 |        |                  |             |\n",
            "| train_fn_340c8_00068 | PENDING    |                   |           32 |      80 |             1 |      0.00982405 |          10 |           2 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00069 | PENDING    |                   |           64 |     700 |            32 |      0.0183811  |          20 |           8 |           4 |        |                  |             |\n",
            "| train_fn_340c8_00070 | PENDING    |                   |           32 |     700 |             2 |      0.00766011 |           1 |           2 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00000 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0249397  |           2 |           1 |           5 |   1000 |       19.1266    |   0.0939492 |\n",
            "| train_fn_340c8_00001 | TERMINATED | 172.28.0.12:18804 |           32 |    1000 |             1 |      0.00721557 |           5 |           1 |           5 |     64 |        1.16897   |   0.0943291 |\n",
            "| train_fn_340c8_00002 | TERMINATED | 172.28.0.12:18804 |           16 |    1000 |             4 |      0.0382463  |           5 |           2 |           5 |     64 |        1.38149   |   0.100224  |\n",
            "| train_fn_340c8_00003 | TERMINATED | 172.28.0.12:18804 |           32 |      60 |             4 |      0.0624976  |           3 |           3 |           5 |     60 |        1.56004   |   0.0929114 |\n",
            "| train_fn_340c8_00004 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0986488  |           1 |           1 |           2 |      1 |        0.0209789 | 307.631     |\n",
            "| train_fn_340c8_00005 | TERMINATED | 172.28.0.12:18804 |           32 |      80 |             1 |      0.0436456  |          30 |           7 |           3 |      4 |        0.079879  |   0.164952  |\n",
            "| train_fn_340c8_00006 | TERMINATED | 172.28.0.12:18804 |           32 |     500 |            64 |      0.0182318  |          25 |           7 |           1 |      1 |        0.0291367 |   2.26371   |\n",
            "| train_fn_340c8_00007 | TERMINATED | 172.28.0.12:18804 |           64 |      60 |            16 |      0.0212547  |          15 |           8 |           2 |     60 |        0.915847  |   0.0932016 |\n",
            "| train_fn_340c8_00008 | TERMINATED | 172.28.0.12:18804 |           16 |      80 |             4 |      0.0194434  |          15 |           6 |           2 |      2 |        0.0614126 |   0.177311  |\n",
            "| train_fn_340c8_00009 | TERMINATED | 172.28.0.12:18804 |           64 |      80 |             2 |      0.00587327 |          25 |           1 |           4 |      1 |        0.0246794 |   0.44166   |\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "... 57 more trials not shown (6 PENDING, 51 TERMINATED)\n",
            "\n",
            "\n",
            "Result for train_fn_340c8_00061:\n",
            "  date: 2023-07-09_21-48-36\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.187512755393982\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.0433807373046875\n",
            "  time_this_iter_s: 0.0433807373046875\n",
            "  time_total_s: 0.0433807373046875\n",
            "  timestamp: 1688939316\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00061\n",
            "  \n",
            "Trial train_fn_340c8_00061 completed.\n",
            "Result for train_fn_340c8_00062:\n",
            "  date: 2023-07-09_21-48-37\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.1897348165512085\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.026432037353515625\n",
            "  time_this_iter_s: 0.026432037353515625\n",
            "  time_total_s: 0.026432037353515625\n",
            "  timestamp: 1688939317\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00062\n",
            "  \n",
            "Trial train_fn_340c8_00062 completed.\n",
            "Result for train_fn_340c8_00063:\n",
            "  date: 2023-07-09_21-48-37\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 188.4990234375\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.07577657699584961\n",
            "  time_this_iter_s: 0.07577657699584961\n",
            "  time_total_s: 0.07577657699584961\n",
            "  timestamp: 1688939317\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00063\n",
            "  \n",
            "Trial train_fn_340c8_00063 completed.\n",
            "Result for train_fn_340c8_00064:\n",
            "  date: 2023-07-09_21-48-37\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.03271364141255617\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.030024290084838867\n",
            "  time_this_iter_s: 0.030024290084838867\n",
            "  time_total_s: 0.030024290084838867\n",
            "  timestamp: 1688939317\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00064\n",
            "  \n",
            "Result for train_fn_340c8_00064:\n",
            "  date: 2023-07-09_21-48-37\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.0719617810100317\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.06793403625488281\n",
            "  time_this_iter_s: 0.037909746170043945\n",
            "  time_total_s: 0.06793403625488281\n",
            "  timestamp: 1688939317\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00064\n",
            "  \n",
            "Trial train_fn_340c8_00064 completed.\n",
            "Result for train_fn_340c8_00065:\n",
            "  date: 2023-07-09_21-48-37\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.09965267032384872\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.01813364028930664\n",
            "  time_this_iter_s: 0.01813364028930664\n",
            "  time_total_s: 0.01813364028930664\n",
            "  timestamp: 1688939317\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00065\n",
            "  \n",
            "Result for train_fn_340c8_00065:\n",
            "  date: 2023-07-09_21-48-37\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.11236148700118065\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.051610708236694336\n",
            "  time_this_iter_s: 0.033477067947387695\n",
            "  time_total_s: 0.051610708236694336\n",
            "  timestamp: 1688939317\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00065\n",
            "  \n",
            "Trial train_fn_340c8_00065 completed.\n",
            "Result for train_fn_340c8_00066:\n",
            "  date: 2023-07-09_21-48-37\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 8.118677139282227\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.018716812133789062\n",
            "  time_this_iter_s: 0.018716812133789062\n",
            "  time_total_s: 0.018716812133789062\n",
            "  timestamp: 1688939317\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00066\n",
            "  \n",
            "Trial train_fn_340c8_00066 completed.\n",
            "Result for train_fn_340c8_00067:\n",
            "  date: 2023-07-09_21-48-37\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.3265634179115295\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.08642125129699707\n",
            "  time_this_iter_s: 0.08642125129699707\n",
            "  time_total_s: 0.08642125129699707\n",
            "  timestamp: 1688939317\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00067\n",
            "  \n",
            "Trial train_fn_340c8_00067 completed.\n",
            "Result for train_fn_340c8_00068:\n",
            "  date: 2023-07-09_21-48-37\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.735202670097351\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.021596908569335938\n",
            "  time_this_iter_s: 0.021596908569335938\n",
            "  time_total_s: 0.021596908569335938\n",
            "  timestamp: 1688939317\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00068\n",
            "  \n",
            "Trial train_fn_340c8_00068 completed.\n",
            "Result for train_fn_340c8_00069:\n",
            "  date: 2023-07-09_21-48-37\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.04110918194055557\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.017386674880981445\n",
            "  time_this_iter_s: 0.017386674880981445\n",
            "  time_total_s: 0.017386674880981445\n",
            "  timestamp: 1688939317\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00069\n",
            "  \n",
            "Result for train_fn_340c8_00069:\n",
            "  date: 2023-07-09_21-48-37\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.19288134574890137\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.04748678207397461\n",
            "  time_this_iter_s: 0.030100107192993164\n",
            "  time_total_s: 0.04748678207397461\n",
            "  timestamp: 1688939317\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00069\n",
            "  \n",
            "Trial train_fn_340c8_00069 completed.\n",
            "Result for train_fn_340c8_00070:\n",
            "  date: 2023-07-09_21-48-37\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.05769684165716171\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.012620925903320312\n",
            "  time_this_iter_s: 0.012620925903320312\n",
            "  time_total_s: 0.012620925903320312\n",
            "  timestamp: 1688939317\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00070\n",
            "  \n",
            "Result for train_fn_340c8_00070:\n",
            "  date: 2023-07-09_21-48-37\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.06673786789178848\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.04088020324707031\n",
            "  time_this_iter_s: 0.02825927734375\n",
            "  time_total_s: 0.04088020324707031\n",
            "  timestamp: 1688939317\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00070\n",
            "  \n",
            "Trial train_fn_340c8_00070 completed.\n",
            "Result for train_fn_340c8_00071:\n",
            "  date: 2023-07-09_21-48-38\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.05483026057481766\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.025206327438354492\n",
            "  time_this_iter_s: 0.025206327438354492\n",
            "  time_total_s: 0.025206327438354492\n",
            "  timestamp: 1688939318\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00071\n",
            "  \n",
            "Result for train_fn_340c8_00071:\n",
            "  date: 2023-07-09_21-48-38\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 16\n",
            "  loss: 0.1731649488210678\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.4100832939147949\n",
            "  time_this_iter_s: 0.02268505096435547\n",
            "  time_total_s: 0.4100832939147949\n",
            "  timestamp: 1688939318\n",
            "  training_iteration: 16\n",
            "  trial_id: 340c8_00071\n",
            "  \n",
            "Trial train_fn_340c8_00071 completed.\n",
            "Result for train_fn_340c8_00072:\n",
            "  date: 2023-07-09_21-48-38\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.31486713886260986\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.04206585884094238\n",
            "  time_this_iter_s: 0.04206585884094238\n",
            "  time_total_s: 0.04206585884094238\n",
            "  timestamp: 1688939318\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00072\n",
            "  \n",
            "Trial train_fn_340c8_00072 completed.\n",
            "Result for train_fn_340c8_00073:\n",
            "  date: 2023-07-09_21-48-38\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 43.42219924926758\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.07383942604064941\n",
            "  time_this_iter_s: 0.07383942604064941\n",
            "  time_total_s: 0.07383942604064941\n",
            "  timestamp: 1688939318\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00073\n",
            "  \n",
            "Trial train_fn_340c8_00073 completed.\n",
            "Result for train_fn_340c8_00074:\n",
            "  date: 2023-07-09_21-48-38\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 14.389972686767578\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.11058902740478516\n",
            "  time_this_iter_s: 0.11058902740478516\n",
            "  time_total_s: 0.11058902740478516\n",
            "  timestamp: 1688939318\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00074\n",
            "  \n",
            "Trial train_fn_340c8_00074 completed.\n",
            "Result for train_fn_340c8_00075:\n",
            "  date: 2023-07-09_21-48-38\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.029132278636097908\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.02312302589416504\n",
            "  time_this_iter_s: 0.02312302589416504\n",
            "  time_total_s: 0.02312302589416504\n",
            "  timestamp: 1688939318\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00075\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2023-07-09 21:48:46 (running for 00:01:16.21)\n",
            "Using AsyncHyperBand: num_stopped=73\n",
            "Bracket: Iter 512.000: -0.0648288894444704 | Iter 256.000: -0.06187822576612234 | Iter 128.000: -0.09052281826734543 | Iter 64.000: -0.09332925453782082 | Iter 32.000: -0.09515061974525452 | Iter 16.000: -0.09637188911437988 | Iter 8.000: -0.09144458547234535 | Iter 4.000: -0.10199407860636711 | Iter 2.000: -0.06347945518791676 | Iter 1.000: -0.18613174557685852\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs\n",
            "Current best trial: 340c8_00075 with loss=0.03112977184355259 and parameters={'batch_size': 32, 'hidden_size': 4, 'num_layer': 5, 'epoch': 100, 'learning_rate': 0.006203800558599818, 'ds': <__main__.CustomDataset object at 0x7f6fe863c250>, 'test_ds': <__main__.CustomDataset object at 0x7f6fe863c190>, 'input_size': 832, 'tolerance': 3, 'min_delta': 3}\n",
            "Result logdir: /root/ray_results/train_fn_2023-07-09_21-47-30\n",
            "Number of trials: 92/100 (16 PENDING, 1 RUNNING, 75 TERMINATED)\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "| Trial name           | status     | loc               |   batch_size |   epoch |   hidden_size |   learning_rate |   min_delta |   num_layer |   tolerance |   iter |   total time (s) |        loss |\n",
            "|----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------|\n",
            "| train_fn_340c8_00075 | RUNNING    | 172.28.0.12:18804 |           32 |     100 |             4 |      0.0062038  |           3 |           5 |           3 |      2 |        0.0553768 |   0.0311298 |\n",
            "| train_fn_340c8_00076 | PENDING    |                   |           64 |     700 |             4 |      0.0220475  |          15 |           2 |           4 |        |                  |             |\n",
            "| train_fn_340c8_00077 | PENDING    |                   |           32 |     500 |             2 |      0.0413875  |           1 |           2 |           4 |        |                  |             |\n",
            "| train_fn_340c8_00078 | PENDING    |                   |           64 |     700 |           256 |      0.0114479  |           2 |           2 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00079 | PENDING    |                   |           64 |     500 |            32 |      0.0558587  |           3 |           1 |           4 |        |                  |             |\n",
            "| train_fn_340c8_00080 | PENDING    |                   |           16 |     700 |             1 |      0.071672   |          25 |           5 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00081 | PENDING    |                   |           16 |     200 |             4 |      0.0262946  |           2 |           5 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00082 | PENDING    |                   |           16 |      80 |           256 |      0.0065818  |          25 |           1 |           5 |        |                  |             |\n",
            "| train_fn_340c8_00083 | PENDING    |                   |           32 |     100 |             4 |      0.0987023  |          10 |           1 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00084 | PENDING    |                   |           32 |     500 |            64 |      0.00920731 |          15 |           4 |           1 |        |                  |             |\n",
            "| train_fn_340c8_00085 | PENDING    |                   |           16 |     150 |            32 |      0.00637884 |          20 |           1 |           3 |        |                  |             |\n",
            "| train_fn_340c8_00000 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0249397  |           2 |           1 |           5 |   1000 |       19.1266    |   0.0939492 |\n",
            "| train_fn_340c8_00001 | TERMINATED | 172.28.0.12:18804 |           32 |    1000 |             1 |      0.00721557 |           5 |           1 |           5 |     64 |        1.16897   |   0.0943291 |\n",
            "| train_fn_340c8_00002 | TERMINATED | 172.28.0.12:18804 |           16 |    1000 |             4 |      0.0382463  |           5 |           2 |           5 |     64 |        1.38149   |   0.100224  |\n",
            "| train_fn_340c8_00003 | TERMINATED | 172.28.0.12:18804 |           32 |      60 |             4 |      0.0624976  |           3 |           3 |           5 |     60 |        1.56004   |   0.0929114 |\n",
            "| train_fn_340c8_00004 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0986488  |           1 |           1 |           2 |      1 |        0.0209789 | 307.631     |\n",
            "| train_fn_340c8_00005 | TERMINATED | 172.28.0.12:18804 |           32 |      80 |             1 |      0.0436456  |          30 |           7 |           3 |      4 |        0.079879  |   0.164952  |\n",
            "| train_fn_340c8_00006 | TERMINATED | 172.28.0.12:18804 |           32 |     500 |            64 |      0.0182318  |          25 |           7 |           1 |      1 |        0.0291367 |   2.26371   |\n",
            "| train_fn_340c8_00007 | TERMINATED | 172.28.0.12:18804 |           64 |      60 |            16 |      0.0212547  |          15 |           8 |           2 |     60 |        0.915847  |   0.0932016 |\n",
            "| train_fn_340c8_00008 | TERMINATED | 172.28.0.12:18804 |           16 |      80 |             4 |      0.0194434  |          15 |           6 |           2 |      2 |        0.0614126 |   0.177311  |\n",
            "| train_fn_340c8_00009 | TERMINATED | 172.28.0.12:18804 |           64 |      80 |             2 |      0.00587327 |          25 |           1 |           4 |      1 |        0.0246794 |   0.44166   |\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "... 72 more trials not shown (6 PENDING, 65 TERMINATED)\n",
            "\n",
            "\n",
            "Result for train_fn_340c8_00075:\n",
            "  date: 2023-07-09_21-48-39\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 3\n",
            "  loss: 0.03907065466046333\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.13268494606018066\n",
            "  time_this_iter_s: 0.07730817794799805\n",
            "  time_total_s: 0.13268494606018066\n",
            "  timestamp: 1688939319\n",
            "  training_iteration: 3\n",
            "  trial_id: 340c8_00075\n",
            "  \n",
            "Result for train_fn_340c8_00075:\n",
            "  date: 2023-07-09_21-48-46\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 8\n",
            "  loss: 0.1423627734184265\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 7.632904767990112\n",
            "  time_this_iter_s: 0.01647329330444336\n",
            "  time_total_s: 7.632904767990112\n",
            "  timestamp: 1688939326\n",
            "  training_iteration: 8\n",
            "  trial_id: 340c8_00075\n",
            "  \n",
            "Trial train_fn_340c8_00075 completed.\n",
            "Result for train_fn_340c8_00076:\n",
            "  date: 2023-07-09_21-48-46\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6238075494766235\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.00922393798828125\n",
            "  time_this_iter_s: 0.00922393798828125\n",
            "  time_total_s: 0.00922393798828125\n",
            "  timestamp: 1688939326\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00076\n",
            "  \n",
            "Trial train_fn_340c8_00076 completed.\n",
            "Result for train_fn_340c8_00077:\n",
            "  date: 2023-07-09_21-48-46\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.4500297009944916\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.01193380355834961\n",
            "  time_this_iter_s: 0.01193380355834961\n",
            "  time_total_s: 0.01193380355834961\n",
            "  timestamp: 1688939326\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00077\n",
            "  \n",
            "Trial train_fn_340c8_00077 completed.\n",
            "Result for train_fn_340c8_00078:\n",
            "  date: 2023-07-09_21-48-46\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 18.575777053833008\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.024407625198364258\n",
            "  time_this_iter_s: 0.024407625198364258\n",
            "  time_total_s: 0.024407625198364258\n",
            "  timestamp: 1688939326\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00078\n",
            "  \n",
            "Trial train_fn_340c8_00078 completed.\n",
            "Result for train_fn_340c8_00079:\n",
            "  date: 2023-07-09_21-48-46\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 5.236205101013184\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.012348413467407227\n",
            "  time_this_iter_s: 0.012348413467407227\n",
            "  time_total_s: 0.012348413467407227\n",
            "  timestamp: 1688939326\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00079\n",
            "  \n",
            "Trial train_fn_340c8_00079 completed.\n",
            "Result for train_fn_340c8_00080:\n",
            "  date: 2023-07-09_21-48-46\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.0328907668590546\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.018468618392944336\n",
            "  time_this_iter_s: 0.018468618392944336\n",
            "  time_total_s: 0.018468618392944336\n",
            "  timestamp: 1688939326\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00080\n",
            "  \n",
            "Trial train_fn_340c8_00080 completed.\n",
            "Result for train_fn_340c8_00081:\n",
            "  date: 2023-07-09_21-48-46\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.14955084025859833\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.01982283592224121\n",
            "  time_this_iter_s: 0.01982283592224121\n",
            "  time_total_s: 0.01982283592224121\n",
            "  timestamp: 1688939326\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00081\n",
            "  \n",
            "Result for train_fn_340c8_00081:\n",
            "  date: 2023-07-09_21-48-46\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.20175789669156075\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.04352164268493652\n",
            "  time_this_iter_s: 0.023698806762695312\n",
            "  time_total_s: 0.04352164268493652\n",
            "  timestamp: 1688939326\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00081\n",
            "  \n",
            "Trial train_fn_340c8_00081 completed.\n",
            "Result for train_fn_340c8_00082:\n",
            "  date: 2023-07-09_21-48-46\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.08590036444365978\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.03742384910583496\n",
            "  time_this_iter_s: 0.03742384910583496\n",
            "  time_total_s: 0.03742384910583496\n",
            "  timestamp: 1688939326\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00082\n",
            "  \n",
            "Result for train_fn_340c8_00082:\n",
            "  date: 2023-07-09_21-48-46\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.21235451847314835\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.061963796615600586\n",
            "  time_this_iter_s: 0.024539947509765625\n",
            "  time_total_s: 0.061963796615600586\n",
            "  timestamp: 1688939326\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00082\n",
            "  \n",
            "Trial train_fn_340c8_00082 completed.\n",
            "Result for train_fn_340c8_00083:\n",
            "  date: 2023-07-09_21-48-46\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.26501351594924927\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.010693788528442383\n",
            "  time_this_iter_s: 0.010693788528442383\n",
            "  time_total_s: 0.010693788528442383\n",
            "  timestamp: 1688939326\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00083\n",
            "  \n",
            "Trial train_fn_340c8_00083 completed.\n",
            "Result for train_fn_340c8_00084:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.2340293526649475\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.014724493026733398\n",
            "  time_this_iter_s: 0.014724493026733398\n",
            "  time_total_s: 0.014724493026733398\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00084\n",
            "  \n",
            "Trial train_fn_340c8_00084 completed.\n",
            "Result for train_fn_340c8_00085:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.0866315234452486\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.01212763786315918\n",
            "  time_this_iter_s: 0.01212763786315918\n",
            "  time_total_s: 0.01212763786315918\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00085\n",
            "  \n",
            "Result for train_fn_340c8_00085:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.1099722757935524\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.08005475997924805\n",
            "  time_this_iter_s: 0.02137160301208496\n",
            "  time_total_s: 0.08005475997924805\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 4\n",
            "  trial_id: 340c8_00085\n",
            "  \n",
            "Trial train_fn_340c8_00085 completed.\n",
            "Result for train_fn_340c8_00086:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.10652174800634384\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.00921630859375\n",
            "  time_this_iter_s: 0.00921630859375\n",
            "  time_total_s: 0.00921630859375\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00086\n",
            "  \n",
            "Result for train_fn_340c8_00086:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.19324374198913574\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.028156042098999023\n",
            "  time_this_iter_s: 0.018939733505249023\n",
            "  time_total_s: 0.028156042098999023\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00086\n",
            "  \n",
            "Trial train_fn_340c8_00086 completed.\n",
            "Result for train_fn_340c8_00087:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 2.311760902404785\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.04262065887451172\n",
            "  time_this_iter_s: 0.04262065887451172\n",
            "  time_total_s: 0.04262065887451172\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00087\n",
            "  \n",
            "Trial train_fn_340c8_00087 completed.\n",
            "Result for train_fn_340c8_00088:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 14.990874290466309\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.05237102508544922\n",
            "  time_this_iter_s: 0.05237102508544922\n",
            "  time_total_s: 0.05237102508544922\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00088\n",
            "  \n",
            "Trial train_fn_340c8_00088 completed.\n",
            "Result for train_fn_340c8_00089:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.06219536438584328\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.010874032974243164\n",
            "  time_this_iter_s: 0.010874032974243164\n",
            "  time_total_s: 0.010874032974243164\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00089\n",
            "  \n",
            "Result for train_fn_340c8_00089:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.07985915243625641\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.03163719177246094\n",
            "  time_this_iter_s: 0.020763158798217773\n",
            "  time_total_s: 0.03163719177246094\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00089\n",
            "  \n",
            "Trial train_fn_340c8_00089 completed.\n",
            "Result for train_fn_340c8_00090:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.029442492872476578\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.016244888305664062\n",
            "  time_this_iter_s: 0.016244888305664062\n",
            "  time_total_s: 0.016244888305664062\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00090\n",
            "  \n",
            "Result for train_fn_340c8_00090:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.16411254554986954\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.04158210754394531\n",
            "  time_this_iter_s: 0.02533721923828125\n",
            "  time_total_s: 0.04158210754394531\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00090\n",
            "  \n",
            "Trial train_fn_340c8_00090 completed.\n",
            "Result for train_fn_340c8_00091:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.161895513534546\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.008680343627929688\n",
            "  time_this_iter_s: 0.008680343627929688\n",
            "  time_total_s: 0.008680343627929688\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00091\n",
            "  \n",
            "Trial train_fn_340c8_00091 completed.\n",
            "Result for train_fn_340c8_00092:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.06569887883961201\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.01163029670715332\n",
            "  time_this_iter_s: 0.01163029670715332\n",
            "  time_total_s: 0.01163029670715332\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00092\n",
            "  \n",
            "Result for train_fn_340c8_00092:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.2900904342532158\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.03375053405761719\n",
            "  time_this_iter_s: 0.022120237350463867\n",
            "  time_total_s: 0.03375053405761719\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00092\n",
            "  \n",
            "Trial train_fn_340c8_00092 completed.\n",
            "Result for train_fn_340c8_00093:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.15285053849220276\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.01078343391418457\n",
            "  time_this_iter_s: 0.01078343391418457\n",
            "  time_total_s: 0.01078343391418457\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00093\n",
            "  \n",
            "Result for train_fn_340c8_00093:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.23199155926704407\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.029133319854736328\n",
            "  time_this_iter_s: 0.018349885940551758\n",
            "  time_total_s: 0.029133319854736328\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 2\n",
            "  trial_id: 340c8_00093\n",
            "  \n",
            "Trial train_fn_340c8_00093 completed.\n",
            "Result for train_fn_340c8_00094:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8904504477977753\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.014124870300292969\n",
            "  time_this_iter_s: 0.014124870300292969\n",
            "  time_total_s: 0.014124870300292969\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00094\n",
            "  \n",
            "Trial train_fn_340c8_00094 completed.\n",
            "Result for train_fn_340c8_00095:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 19.02098274230957\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.07985377311706543\n",
            "  time_this_iter_s: 0.07985377311706543\n",
            "  time_total_s: 0.07985377311706543\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00095\n",
            "  \n",
            "Trial train_fn_340c8_00095 completed.\n",
            "Result for train_fn_340c8_00096:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7832430005073547\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.012715578079223633\n",
            "  time_this_iter_s: 0.012715578079223633\n",
            "  time_total_s: 0.012715578079223633\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00096\n",
            "  \n",
            "Trial train_fn_340c8_00096 completed.\n",
            "Result for train_fn_340c8_00097:\n",
            "  date: 2023-07-09_21-48-47\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.555505633354187\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.00603485107421875\n",
            "  time_this_iter_s: 0.00603485107421875\n",
            "  time_total_s: 0.00603485107421875\n",
            "  timestamp: 1688939327\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00097\n",
            "  \n",
            "Trial train_fn_340c8_00097 completed.\n",
            "Result for train_fn_340c8_00098:\n",
            "  date: 2023-07-09_21-48-48\n",
            "  done: false\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.03343670442700386\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.01793646812438965\n",
            "  time_this_iter_s: 0.01793646812438965\n",
            "  time_total_s: 0.01793646812438965\n",
            "  timestamp: 1688939328\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00098\n",
            "  \n",
            "Result for train_fn_340c8_00098:\n",
            "  date: 2023-07-09_21-48-48\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.22609655559062958\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.07920098304748535\n",
            "  time_this_iter_s: 0.019843339920043945\n",
            "  time_total_s: 0.07920098304748535\n",
            "  timestamp: 1688939328\n",
            "  training_iteration: 4\n",
            "  trial_id: 340c8_00098\n",
            "  \n",
            "Trial train_fn_340c8_00098 completed.\n",
            "Result for train_fn_340c8_00099:\n",
            "  date: 2023-07-09_21-48-48\n",
            "  done: true\n",
            "  hostname: f11c9abbb306\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.2408384382724762\n",
            "  node_ip: 172.28.0.12\n",
            "  pid: 18804\n",
            "  time_since_restore: 0.005963802337646484\n",
            "  time_this_iter_s: 0.005963802337646484\n",
            "  time_total_s: 0.005963802337646484\n",
            "  timestamp: 1688939328\n",
            "  training_iteration: 1\n",
            "  trial_id: 340c8_00099\n",
            "  \n",
            "Trial train_fn_340c8_00099 completed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-09 21:48:53,802\tINFO tune.py:1111 -- Total run time: 83.65 seconds (77.92 seconds for the tuning loop).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Current time: 2023-07-09 21:48:53 (running for 00:01:23.55)\n",
            "Using AsyncHyperBand: num_stopped=98\n",
            "Bracket: Iter 512.000: -0.0648288894444704 | Iter 256.000: -0.06187822576612234 | Iter 128.000: -0.09052281826734543 | Iter 64.000: -0.09332925453782082 | Iter 32.000: -0.09515061974525452 | Iter 16.000: -0.09637188911437988 | Iter 8.000: -0.09207047335803509 | Iter 4.000: -0.10598317719995975 | Iter 2.000: -0.06855723634362221 | Iter 1.000: -0.2143552526831627\n",
            "Logical resource usage: 1.0/2 CPUs, 1.0/1 GPUs\n",
            "Current best trial: 340c8_00021 with loss=0.043258946388959885 and parameters={'batch_size': 32, 'hidden_size': 4, 'num_layer': 3, 'epoch': 1000, 'learning_rate': 0.019453390933782167, 'ds': <__main__.CustomDataset object at 0x7f6fe84d28c0>, 'test_ds': <__main__.CustomDataset object at 0x7f6fe84b5360>, 'input_size': 832, 'tolerance': 2, 'min_delta': 25}\n",
            "Result logdir: /root/ray_results/train_fn_2023-07-09_21-47-30\n",
            "Number of trials: 100/100 (100 TERMINATED)\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "| Trial name           | status     | loc               |   batch_size |   epoch |   hidden_size |   learning_rate |   min_delta |   num_layer |   tolerance |   iter |   total time (s) |        loss |\n",
            "|----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------|\n",
            "| train_fn_340c8_00000 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0249397  |           2 |           1 |           5 |   1000 |      19.1266     |   0.0939492 |\n",
            "| train_fn_340c8_00001 | TERMINATED | 172.28.0.12:18804 |           32 |    1000 |             1 |      0.00721557 |           5 |           1 |           5 |     64 |       1.16897    |   0.0943291 |\n",
            "| train_fn_340c8_00002 | TERMINATED | 172.28.0.12:18804 |           16 |    1000 |             4 |      0.0382463  |           5 |           2 |           5 |     64 |       1.38149    |   0.100224  |\n",
            "| train_fn_340c8_00003 | TERMINATED | 172.28.0.12:18804 |           32 |      60 |             4 |      0.0624976  |           3 |           3 |           5 |     60 |       1.56004    |   0.0929114 |\n",
            "| train_fn_340c8_00004 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |           256 |      0.0986488  |           1 |           1 |           2 |      1 |       0.0209789  | 307.631     |\n",
            "| train_fn_340c8_00005 | TERMINATED | 172.28.0.12:18804 |           32 |      80 |             1 |      0.0436456  |          30 |           7 |           3 |      4 |       0.079879   |   0.164952  |\n",
            "| train_fn_340c8_00006 | TERMINATED | 172.28.0.12:18804 |           32 |     500 |            64 |      0.0182318  |          25 |           7 |           1 |      1 |       0.0291367  |   2.26371   |\n",
            "| train_fn_340c8_00007 | TERMINATED | 172.28.0.12:18804 |           64 |      60 |            16 |      0.0212547  |          15 |           8 |           2 |     60 |       0.915847   |   0.0932016 |\n",
            "| train_fn_340c8_00008 | TERMINATED | 172.28.0.12:18804 |           16 |      80 |             4 |      0.0194434  |          15 |           6 |           2 |      2 |       0.0614126  |   0.177311  |\n",
            "| train_fn_340c8_00009 | TERMINATED | 172.28.0.12:18804 |           64 |      80 |             2 |      0.00587327 |          25 |           1 |           4 |      1 |       0.0246794  |   0.44166   |\n",
            "| train_fn_340c8_00010 | TERMINATED | 172.28.0.12:18804 |           32 |     150 |           256 |      0.0136777  |          30 |           7 |           5 |      1 |       0.100848   |   2.037     |\n",
            "| train_fn_340c8_00011 | TERMINATED | 172.28.0.12:18804 |           16 |      80 |            64 |      0.0171157  |           5 |           7 |           4 |     32 |       1.12861    |   0.100246  |\n",
            "| train_fn_340c8_00012 | TERMINATED | 172.28.0.12:18804 |           16 |     150 |           256 |      0.00852635 |          20 |           3 |           1 |      4 |       0.196656   |   0.169638  |\n",
            "| train_fn_340c8_00013 | TERMINATED | 172.28.0.12:18804 |           16 |     100 |            32 |      0.0240211  |          30 |           1 |           1 |      1 |       0.0235088  |   0.356515  |\n",
            "| train_fn_340c8_00014 | TERMINATED | 172.28.0.12:18804 |           32 |     700 |            32 |      0.0486621  |           1 |           3 |           5 |      1 |       0.0144906  |   1.74639   |\n",
            "| train_fn_340c8_00015 | TERMINATED | 172.28.0.12:18804 |           16 |     100 |             8 |      0.00636152 |          25 |           5 |           3 |      4 |       0.134275   |   0.184199  |\n",
            "| train_fn_340c8_00016 | TERMINATED | 172.28.0.12:18804 |           64 |     500 |             4 |      0.022412   |          15 |           7 |           3 |      1 |       0.0153716  |   0.784364  |\n",
            "| train_fn_340c8_00017 | TERMINATED | 172.28.0.12:18804 |           64 |     500 |            32 |      0.021546   |           2 |           5 |           3 |      4 |       0.101241   |   0.231935  |\n",
            "| train_fn_340c8_00018 | TERMINATED | 172.28.0.12:18804 |           32 |     150 |             2 |      0.0859522  |          25 |           6 |           3 |      4 |       0.101873   |   0.265368  |\n",
            "| train_fn_340c8_00019 | TERMINATED | 172.28.0.12:18804 |           64 |     700 |             1 |      0.0798663  |           1 |           7 |           3 |      2 |       0.0433006  |   0.120525  |\n",
            "| train_fn_340c8_00020 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |             4 |      0.033486   |           3 |           5 |           5 |      1 |       0.0120025  |   0.300237  |\n",
            "| train_fn_340c8_00021 | TERMINATED | 172.28.0.12:18804 |           32 |    1000 |             4 |      0.0194534  |          25 |           3 |           2 |   1000 |      22.7695     |   0.0432589 |\n",
            "| train_fn_340c8_00022 | TERMINATED | 172.28.0.12:18804 |           32 |     100 |            64 |      0.0159701  |          25 |           2 |           4 |      1 |       0.0244596  |   0.194681  |\n",
            "| train_fn_340c8_00023 | TERMINATED | 172.28.0.12:18804 |           64 |      80 |             2 |      0.0146679  |          10 |           8 |           3 |      1 |       0.0165589  |   0.491733  |\n",
            "| train_fn_340c8_00024 | TERMINATED | 172.28.0.12:18804 |           16 |     150 |             4 |      0.0752408  |          25 |           8 |           3 |      8 |       0.221048   |   0.111684  |\n",
            "| train_fn_340c8_00025 | TERMINATED | 172.28.0.12:18804 |           64 |      80 |           128 |      0.00636581 |           5 |           7 |           2 |      2 |       0.058301   |   0.108022  |\n",
            "| train_fn_340c8_00026 | TERMINATED | 172.28.0.12:18804 |           64 |     100 |           256 |      0.00961102 |          30 |           2 |           1 |      1 |       0.0241826  |  14.0619    |\n",
            "| train_fn_340c8_00027 | TERMINATED | 172.28.0.12:18804 |           32 |     500 |            16 |      0.00503378 |          20 |           7 |           2 |      1 |       0.0143292  |   0.293164  |\n",
            "| train_fn_340c8_00028 | TERMINATED | 172.28.0.12:18804 |           32 |     100 |             1 |      0.00864621 |           2 |           2 |           5 |     32 |       0.519616   |   0.0952968 |\n",
            "| train_fn_340c8_00029 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |            32 |      0.00574987 |           5 |           6 |           1 |      2 |       0.0356989  |   0.101832  |\n",
            "| train_fn_340c8_00030 | TERMINATED | 172.28.0.12:18804 |           32 |      80 |            64 |      0.033664   |           5 |           2 |           3 |     64 |       1.0818     |   0.0934686 |\n",
            "| train_fn_340c8_00031 | TERMINATED | 172.28.0.12:18804 |           16 |     500 |           128 |      0.00716747 |          10 |           8 |           2 |     16 |       0.513031   |   0.0996549 |\n",
            "| train_fn_340c8_00032 | TERMINATED | 172.28.0.12:18804 |           16 |     200 |             8 |      0.00708865 |          25 |           2 |           4 |      4 |       0.0865874  |   0.234396  |\n",
            "| train_fn_340c8_00033 | TERMINATED | 172.28.0.12:18804 |           16 |     200 |            32 |      0.0643573  |          15 |           5 |           1 |    128 |       2.92044    |   0.0914677 |\n",
            "| train_fn_340c8_00034 | TERMINATED | 172.28.0.12:18804 |           32 |     500 |            16 |      0.0628009  |           3 |           1 |           5 |      1 |       0.0129092  |   0.467088  |\n",
            "| train_fn_340c8_00035 | TERMINATED | 172.28.0.12:18804 |           16 |      80 |            64 |      0.00558762 |          30 |           3 |           1 |      1 |       0.0232568  |   0.377864  |\n",
            "| train_fn_340c8_00036 | TERMINATED | 172.28.0.12:18804 |           64 |      60 |           256 |      0.0956341  |           2 |           1 |           5 |      1 |       0.0207827  | 260.577     |\n",
            "| train_fn_340c8_00037 | TERMINATED | 172.28.0.12:18804 |           32 |     500 |            16 |      0.00803276 |           3 |           5 |           3 |      1 |       0.0159509  |   0.295761  |\n",
            "| train_fn_340c8_00038 | TERMINATED | 172.28.0.12:18804 |           16 |     700 |            32 |      0.0262573  |          20 |           6 |           3 |      8 |       0.262395   |   0.116429  |\n",
            "| train_fn_340c8_00039 | TERMINATED | 172.28.0.12:18804 |           32 |      80 |           256 |      0.0572701  |          20 |           6 |           2 |      1 |       0.0525954  |  23.5895    |\n",
            "| train_fn_340c8_00040 | TERMINATED | 172.28.0.12:18804 |           16 |     100 |             1 |      0.0277341  |           3 |           1 |           4 |      8 |       0.174883   |   0.144455  |\n",
            "| train_fn_340c8_00041 | TERMINATED | 172.28.0.12:18804 |           16 |     700 |           128 |      0.0594896  |          15 |           7 |           3 |      1 |       0.0544865  |   2.69929   |\n",
            "| train_fn_340c8_00042 | TERMINATED | 172.28.0.12:18804 |           64 |     200 |            16 |      0.0712592  |          10 |           6 |           1 |      4 |       0.0915515  |   0.169257  |\n",
            "| train_fn_340c8_00043 | TERMINATED | 172.28.0.12:18804 |           32 |     100 |             4 |      0.0181705  |           5 |           2 |           2 |      1 |       0.0126297  |   0.374646  |\n",
            "| train_fn_340c8_00044 | TERMINATED | 172.28.0.12:18804 |           32 |      80 |            32 |      0.0631437  |           1 |           5 |           5 |      2 |       0.0747099  |   0.22093   |\n",
            "| train_fn_340c8_00045 | TERMINATED | 172.28.0.12:18804 |           64 |      60 |             2 |      0.00950874 |          25 |           8 |           2 |      1 |       0.0134828  |   0.291378  |\n",
            "| train_fn_340c8_00046 | TERMINATED | 172.28.0.12:18804 |           64 |     150 |             2 |      0.00887302 |           5 |           2 |           5 |     32 |       0.922661   |   0.11772   |\n",
            "| train_fn_340c8_00047 | TERMINATED | 172.28.0.12:18804 |           32 |    1000 |            32 |      0.0353193  |          10 |           8 |           3 |      8 |       0.216141   |   0.110588  |\n",
            "| train_fn_340c8_00048 | TERMINATED | 172.28.0.12:18804 |           64 |     500 |             2 |      0.0556438  |          15 |           7 |           5 |      4 |       0.0790203  |   0.149032  |\n",
            "| train_fn_340c8_00049 | TERMINATED | 172.28.0.12:18804 |           64 |      80 |            64 |      0.00855116 |           1 |           6 |           3 |      4 |       0.0889573  |   0.147352  |\n",
            "| train_fn_340c8_00050 | TERMINATED | 172.28.0.12:18804 |           64 |     500 |            32 |      0.0130506  |          15 |           1 |           4 |      1 |       0.00938678 |   1.23459   |\n",
            "| train_fn_340c8_00051 | TERMINATED | 172.28.0.12:18804 |           64 |     150 |            16 |      0.078701   |           1 |           2 |           3 |      1 |       0.00877738 |   0.480913  |\n",
            "| train_fn_340c8_00052 | TERMINATED | 172.28.0.12:18804 |           16 |     100 |           256 |      0.019184   |          20 |           6 |           1 |      1 |       0.0909231  |   2.57052   |\n",
            "| train_fn_340c8_00053 | TERMINATED | 172.28.0.12:18804 |           16 |     500 |             8 |      0.0905751  |           2 |           7 |           3 |      2 |       0.0813899  |   0.120838  |\n",
            "| train_fn_340c8_00054 | TERMINATED | 172.28.0.12:18804 |           32 |     100 |           128 |      0.0121552  |           1 |           4 |           4 |     32 |       0.846945   |   0.0960314 |\n",
            "| train_fn_340c8_00055 | TERMINATED | 172.28.0.12:18804 |           16 |    1000 |           128 |      0.0428246  |          10 |           3 |           1 |      1 |       0.0343714  |   1.25682   |\n",
            "| train_fn_340c8_00056 | TERMINATED | 172.28.0.12:18804 |           32 |    1000 |            32 |      0.0504488  |          30 |           8 |           5 |      2 |       0.0643203  |   0.263334  |\n",
            "| train_fn_340c8_00057 | TERMINATED | 172.28.0.12:18804 |           32 |     150 |           256 |      0.0137935  |           3 |           2 |           4 |      1 |       0.0374346  |   0.970222  |\n",
            "| train_fn_340c8_00058 | TERMINATED | 172.28.0.12:18804 |           16 |     100 |             1 |      0.0138488  |          10 |           7 |           4 |      1 |       0.0264044  |   1.1302    |\n",
            "| train_fn_340c8_00059 | TERMINATED | 172.28.0.12:18804 |           32 |     150 |             4 |      0.00512237 |          25 |           4 |           3 |     16 |       0.372935   |   0.111736  |\n",
            "| train_fn_340c8_00060 | TERMINATED | 172.28.0.12:18804 |           16 |    1000 |            16 |      0.0730998  |          25 |           2 |           5 |      4 |       0.111478   |   0.165038  |\n",
            "| train_fn_340c8_00061 | TERMINATED | 172.28.0.12:18804 |           32 |      60 |           128 |      0.00704577 |          30 |           5 |           5 |      1 |       0.0433807  |   1.18751   |\n",
            "| train_fn_340c8_00062 | TERMINATED | 172.28.0.12:18804 |           32 |     150 |             4 |      0.00621334 |           1 |           5 |           3 |      1 |       0.026432   |   0.189735  |\n",
            "| train_fn_340c8_00063 | TERMINATED | 172.28.0.12:18804 |           64 |     500 |           256 |      0.0709445  |           5 |           6 |           1 |      1 |       0.0757766  | 188.499     |\n",
            "| train_fn_340c8_00064 | TERMINATED | 172.28.0.12:18804 |           16 |     150 |             8 |      0.0052856  |          15 |           7 |           1 |      2 |       0.067934   |   0.0719618 |\n",
            "| train_fn_340c8_00065 | TERMINATED | 172.28.0.12:18804 |           16 |      80 |             4 |      0.0114692  |          20 |           1 |           1 |      2 |       0.0516107  |   0.112361  |\n",
            "| train_fn_340c8_00066 | TERMINATED | 172.28.0.12:18804 |           64 |    1000 |            32 |      0.0981438  |           3 |           6 |           3 |      1 |       0.0187168  |   8.11868   |\n",
            "| train_fn_340c8_00067 | TERMINATED | 172.28.0.12:18804 |           16 |     500 |           256 |      0.0409379  |           1 |           6 |           5 |      1 |       0.0864213  |   1.32656   |\n",
            "| train_fn_340c8_00068 | TERMINATED | 172.28.0.12:18804 |           32 |      80 |             1 |      0.00982405 |          10 |           2 |           1 |      1 |       0.0215969  |   1.7352    |\n",
            "| train_fn_340c8_00069 | TERMINATED | 172.28.0.12:18804 |           64 |     700 |            32 |      0.0183811  |          20 |           8 |           4 |      2 |       0.0474868  |   0.192881  |\n",
            "| train_fn_340c8_00070 | TERMINATED | 172.28.0.12:18804 |           32 |     700 |             2 |      0.00766011 |           1 |           2 |           3 |      2 |       0.0408802  |   0.0667379 |\n",
            "| train_fn_340c8_00071 | TERMINATED | 172.28.0.12:18804 |           64 |     200 |             4 |      0.00936807 |           5 |           3 |           4 |     16 |       0.410083   |   0.173165  |\n",
            "| train_fn_340c8_00072 | TERMINATED | 172.28.0.12:18804 |           16 |    1000 |            64 |      0.043548   |           2 |           6 |           5 |      1 |       0.0420659  |   0.314867  |\n",
            "| train_fn_340c8_00073 | TERMINATED | 172.28.0.12:18804 |           64 |     500 |           256 |      0.0236697  |           2 |           6 |           1 |      1 |       0.0738394  |  43.4222    |\n",
            "| train_fn_340c8_00074 | TERMINATED | 172.28.0.12:18804 |           16 |     500 |           256 |      0.0475656  |           5 |           8 |           3 |      1 |       0.110589   |  14.39      |\n",
            "| train_fn_340c8_00075 | TERMINATED | 172.28.0.12:18804 |           32 |     100 |             4 |      0.0062038  |           3 |           5 |           3 |      8 |       7.6329     |   0.142363  |\n",
            "| train_fn_340c8_00076 | TERMINATED | 172.28.0.12:18804 |           64 |     700 |             4 |      0.0220475  |          15 |           2 |           4 |      1 |       0.00922394 |   0.623808  |\n",
            "| train_fn_340c8_00077 | TERMINATED | 172.28.0.12:18804 |           32 |     500 |             2 |      0.0413875  |           1 |           2 |           4 |      1 |       0.0119338  |   0.45003   |\n",
            "| train_fn_340c8_00078 | TERMINATED | 172.28.0.12:18804 |           64 |     700 |           256 |      0.0114479  |           2 |           2 |           1 |      1 |       0.0244076  |  18.5758    |\n",
            "| train_fn_340c8_00079 | TERMINATED | 172.28.0.12:18804 |           64 |     500 |            32 |      0.0558587  |           3 |           1 |           4 |      1 |       0.0123484  |   5.23621   |\n",
            "| train_fn_340c8_00080 | TERMINATED | 172.28.0.12:18804 |           16 |     700 |             1 |      0.071672   |          25 |           5 |           3 |      1 |       0.0184686  |   1.03289   |\n",
            "| train_fn_340c8_00081 | TERMINATED | 172.28.0.12:18804 |           16 |     200 |             4 |      0.0262946  |           2 |           5 |           3 |      2 |       0.0435216  |   0.201758  |\n",
            "| train_fn_340c8_00082 | TERMINATED | 172.28.0.12:18804 |           16 |      80 |           256 |      0.0065818  |          25 |           1 |           5 |      2 |       0.0619638  |   0.212355  |\n",
            "| train_fn_340c8_00083 | TERMINATED | 172.28.0.12:18804 |           32 |     100 |             4 |      0.0987023  |          10 |           1 |           3 |      1 |       0.0106938  |   0.265014  |\n",
            "| train_fn_340c8_00084 | TERMINATED | 172.28.0.12:18804 |           32 |     500 |            64 |      0.00920731 |          15 |           4 |           1 |      1 |       0.0147245  |   0.234029  |\n",
            "| train_fn_340c8_00085 | TERMINATED | 172.28.0.12:18804 |           16 |     150 |            32 |      0.00637884 |          20 |           1 |           3 |      4 |       0.0800548  |   0.109972  |\n",
            "| train_fn_340c8_00086 | TERMINATED | 172.28.0.12:18804 |           32 |      60 |            16 |      0.0183348  |          15 |           3 |           1 |      2 |       0.028156   |   0.193244  |\n",
            "| train_fn_340c8_00087 | TERMINATED | 172.28.0.12:18804 |           16 |      60 |           128 |      0.0606145  |          25 |           7 |           3 |      1 |       0.0426207  |   2.31176   |\n",
            "| train_fn_340c8_00088 | TERMINATED | 172.28.0.12:18804 |           32 |      60 |           256 |      0.042987   |           5 |           6 |           4 |      1 |       0.052371   |  14.9909    |\n",
            "| train_fn_340c8_00089 | TERMINATED | 172.28.0.12:18804 |           32 |      80 |             2 |      0.00714894 |          20 |           6 |           4 |      2 |       0.0316372  |   0.0798592 |\n",
            "| train_fn_340c8_00090 | TERMINATED | 172.28.0.12:18804 |           16 |     500 |            64 |      0.0251523  |          15 |           3 |           2 |      2 |       0.0415821  |   0.164113  |\n",
            "| train_fn_340c8_00091 | TERMINATED | 172.28.0.12:18804 |           32 |      60 |            32 |      0.0199998  |           5 |           1 |           5 |      1 |       0.00868034 |   1.1619    |\n",
            "| train_fn_340c8_00092 | TERMINATED | 172.28.0.12:18804 |           16 |      60 |             1 |      0.0788248  |          10 |           1 |           1 |      2 |       0.0337505  |   0.29009   |\n",
            "| train_fn_340c8_00093 | TERMINATED | 172.28.0.12:18804 |           32 |     500 |             2 |      0.0901701  |           5 |           6 |           1 |      2 |       0.0291333  |   0.231992  |\n",
            "| train_fn_340c8_00094 | TERMINATED | 172.28.0.12:18804 |           16 |     500 |            64 |      0.0617662  |          20 |           1 |           2 |      1 |       0.0141249  |   0.89045   |\n",
            "| train_fn_340c8_00095 | TERMINATED | 172.28.0.12:18804 |           32 |     200 |           256 |      0.0465172  |           2 |           5 |           2 |      1 |       0.0798538  |  19.021     |\n",
            "| train_fn_340c8_00096 | TERMINATED | 172.28.0.12:18804 |           32 |    1000 |             1 |      0.02466    |           1 |           8 |           2 |      1 |       0.0127156  |   0.783243  |\n",
            "| train_fn_340c8_00097 | TERMINATED | 172.28.0.12:18804 |           64 |     700 |             4 |      0.0852152  |           2 |           1 |           1 |      1 |       0.00603485 |   0.555506  |\n",
            "| train_fn_340c8_00098 | TERMINATED | 172.28.0.12:18804 |           32 |     200 |            16 |      0.00990809 |           3 |           2 |           4 |      4 |       0.079201   |   0.226097  |\n",
            "| train_fn_340c8_00099 | TERMINATED | 172.28.0.12:18804 |           64 |      80 |             1 |      0.0904681  |          20 |           1 |           4 |      1 |       0.0059638  |   0.240838  |\n",
            "+----------------------+------------+-------------------+--------------+---------+---------------+-----------------+-------------+-------------+-------------+--------+------------------+-------------+\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "config = {\n",
        "    \"batch_size\": tune.choice([16, 32, 64]),\n",
        "    \"hidden_size\": tune.choice([2 ** i for i in range(9)]),\n",
        "    \"num_layer\": tune.choice([1, 2, 3, 4, 5, 6, 7, 8]),\n",
        "    \"epoch\": tune.choice([60, 80, 100, 150, 200, 500, 700, 1000]),\n",
        "    \"learning_rate\": tune.loguniform(0.005, 0.1),\n",
        "    \"ds\": ds,\n",
        "    \"test_ds\": test_ds,\n",
        "    \"input_size\": 832, #change if you change the input size\n",
        "    \"tolerance\": tune.choice([1, 2, 3, 4, 5]),\n",
        "    \"min_delta\": tune.choice([1, 2, 3, 5, 10, 15, 20, 25, 30])\n",
        "}\n",
        "\n",
        "scheduler = ASHAScheduler(\n",
        "        max_t=1000,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "\n",
        "ray.init(object_store_memory=10**10)\n",
        "tuner = tune.Tuner(\n",
        "        tune.with_resources(\n",
        "            tune.with_parameters(train_fn),\n",
        "            resources={\"cpu\": 1, \"gpu\": 1}\n",
        "        ),\n",
        "        tune_config=tune.TuneConfig(\n",
        "            metric=\"loss\",\n",
        "            mode=\"min\",\n",
        "            scheduler=scheduler,\n",
        "            num_samples=100,\n",
        "        ),\n",
        "        param_space=config,\n",
        "    )\n",
        "results = tuner.fit()\n",
        "\n",
        "best_result = results.get_best_result(\"loss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62pRYuZ3gwpH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62pRYuZ3gwpH",
        "outputId": "4335e02c-d056-4d74-9337-eecbf0325062"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Result(\n",
              "  metrics={'loss': 0.043258946388959885, 'done': True, 'trial_id': '340c8_00021', 'experiment_tag': '21_batch_size=32,epoch=1000,hidden_size=4,learning_rate=0.0195,min_delta=25,num_layer=3,tolerance=2'},\n",
              "  path='/root/ray_results/train_fn_2023-07-09_21-47-30/train_fn_340c8_00021_21_batch_size=32,epoch=1000,hidden_size=4,learning_rate=0.0195,min_delta=25,num_layer=3,tolerance=2_2023-07-09_21-47-58',\n",
              "  checkpoint=None\n",
              ")"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NylIyUlFgwh2",
      "metadata": {
        "id": "NylIyUlFgwh2"
      },
      "outputs": [],
      "source": [
        "best_config = best_result.metrics[\"config\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c828797",
      "metadata": {
        "id": "8c828797"
      },
      "outputs": [],
      "source": [
        "ds = CustomDataset(data_tensor, target_tensor)\n",
        "test_ds = CustomDataset(test_data_tensor, test_target_tensor)\n",
        "#weights_path = os.path.join(data_path, \"model_best_v1.pt\")\n",
        "\n",
        "\n",
        "old_loss = 99999999999\n",
        "\n",
        "train_loader = DataLoader(ds, batch_size=best_config[\"batch_size\"], shuffle=False)\n",
        "\n",
        "test_dataloader = DataLoader(test_ds, batch_size=best_config[\"batch_size\"], shuffle=False)\n",
        "\n",
        "early_stopping = EarlyStopping(tolerance=best_config[\"tolerance\"], min_delta=best_config[\"min_delta\"])\n",
        "\n",
        "#model = ConvLSTM(8, 4, (7,7), 1, True, True, False)\n",
        "model = LSTMModel(best_config[\"input_size\"], best_config[\"hidden_size\"], best_config[\"num_layer\"], 1)\n",
        "model.to(device)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=best_config[\"learning_rate\"])\n",
        "epoch_test_loss = 0\n",
        "\n",
        "for epoch in range(best_config[\"epoch\"]):\n",
        "    epoch_test_loss = []\n",
        "    epoch_loss = []\n",
        "    model.train()\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(batch_x)\n",
        "        loss = criterion(y_pred, batch_y).to(device)\n",
        "        loss.backward()\n",
        "        epoch_loss.append(loss.item())\n",
        "        optimizer.step()\n",
        "    epoch_loss = np.mean(epoch_loss)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_test_x, batch_test_y in test_dataloader:\n",
        "            batch_test_x = batch_test_x.to(device)\n",
        "            batch_test_y = batch_test_y.to(device)\n",
        "            y_test_pred = model(batch_test_x)\n",
        "            test_loss = criterion(y_test_pred, batch_test_y).to(device)\n",
        "            epoch_test_loss.append(test_loss.item())\n",
        "        epoch_test_loss = np.mean(epoch_test_loss)\n",
        "\n",
        "    early_stopping(epoch_loss, epoch_test_loss)\n",
        "    if early_stopping.early_stop:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaa2d4a6-df3d-4a76-92ee-5f1bd89a5a28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaa2d4a6-df3d-4a76-92ee-5f1bd89a5a28",
        "outputId": "9cdb7b68-422f-4020-f6c5-9da1833432f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301], [0.6615985035896301]]\n",
            "MSE: 0.0931\n",
            "R^2: -2.1985\n",
            "MAE: 0.2587\n",
            "[0.6615985035896301] [0.5666666626930237]\n"
          ]
        }
      ],
      "source": [
        "test_ds = CustomDataset(test_data_tensor, test_target_tensor)\n",
        "test_dataloader = DataLoader(test_ds, batch_size=60, shuffle=False)\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "model.cpu()\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch_x, batch_y in test_dataloader:\n",
        "        y_true += batch_y.tolist()\n",
        "        y_pred += model(batch_x).tolist()\n",
        "        print(y_pred)\n",
        "        break\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(y_pred[0], y_true[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06lRzqgYQq0x",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06lRzqgYQq0x",
        "outputId": "0551aeaa-63fa-4340-fee4-cc2151d29aad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60, 3328)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_flat_sequences.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85f6f4c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85f6f4c3",
        "outputId": "6d66149f-7df3-4ae0-976b-670ef764a3f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(27,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "xgb_model = xgb.XGBRegressor()\n",
        "\n",
        "\n",
        "trained_model = xgb_model.fit(train_flat_sequences, train_flat_targets)\n",
        "\n",
        "test_forecasts = trained_model.predict(test_flat_sequences)\n",
        "print(test_forecasts.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dtOtMy5Vudr7",
      "metadata": {
        "id": "dtOtMy5Vudr7"
      },
      "outputs": [],
      "source": [
        "output_data = [test_forecasts, np.reshape(y_pred, (27)), np.reshape(y_true, (27))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n3RzvQCnQjvy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3RzvQCnQjvy",
        "outputId": "76e333ba-a3c9-4291-b883-0836c62d3464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 0.0557\n",
            "MAE: 0.2022\n"
          ]
        }
      ],
      "source": [
        "xgb_mse = mean_squared_error(test_flat_targets, test_forecasts)\n",
        "xgb_mae = mean_absolute_error(test_flat_targets, test_forecasts)\n",
        "\n",
        "print(f\"MSE: {xgb_mse:.4f}\")\n",
        "print(f\"MAE: {xgb_mae:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pinbcvV61u7k",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pinbcvV61u7k",
        "outputId": "0a5d6e93-cdda-4b72-9a1b-a2533a2674e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([0.9084926 , 0.9335689 , 0.9024999 , 0.7234424 , 0.6506613 ,\n",
              "        0.52892673, 0.53050154, 0.41413993, 0.5685187 , 0.66319615,\n",
              "        0.6496903 , 0.79899025, 0.842749  , 0.87705743, 0.7356789 ,\n",
              "        0.49781492, 0.33420777, 0.5090657 , 0.332378  , 0.34916738,\n",
              "        0.312335  , 0.3522084 , 0.37098244, 0.5325278 , 0.57571495,\n",
              "        0.56013685, 0.43078303], dtype=float32),\n",
              " array([0.6615985, 0.6615985, 0.6615985, 0.6615985, 0.6615985, 0.6615985,\n",
              "        0.6615985, 0.6615985, 0.6615985, 0.6615985, 0.6615985, 0.6615985,\n",
              "        0.6615985, 0.6615985, 0.6615985, 0.6615985, 0.6615985, 0.6615985,\n",
              "        0.6615985, 0.6615985, 0.6615985, 0.6615985, 0.6615985, 0.6615985,\n",
              "        0.6615985, 0.6615985, 0.6615985]),\n",
              " array([0.56666666, 0.61666667, 0.58333331, 0.53333336, 0.52777779,\n",
              "        0.38055557, 0.17777778, 0.43611112, 0.57222223, 0.28611112,\n",
              "        0.32222223, 0.6111111 , 0.73888886, 0.58333331, 0.45555556,\n",
              "        0.47499999, 0.5       , 0.23888889, 0.25555557, 0.28611112,\n",
              "        0.        , 0.33333334, 0.48333332, 0.33888888, 0.14444445,\n",
              "        0.36666667, 0.21944444])]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RFQ8v6lT0nF0",
      "metadata": {
        "id": "RFQ8v6lT0nF0"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\"grace_xgboost\": output_data[0], \"grace_lstm\": output_data[1], \"test_data\": output_data[2]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4Xcc1sd-4hRc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "4Xcc1sd-4hRc",
        "outputId": "5671a42d-b930-4d3e-8f0f-3ca842c4aacc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(df, label=[\"xgboost\", \"lstm\", \"test_data\"])\n",
        "leg = plt.legend(loc='upper center')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HWfIQqnu4j4c",
      "metadata": {
        "id": "HWfIQqnu4j4c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
