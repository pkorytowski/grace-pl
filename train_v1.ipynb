{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "056e29ce-356d-4c7a-9660-959071839ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c227f68-1191-4dbb-919b-921fd88a3646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_pickle(\"data/ready_dataset.pickle\")\n",
    "print(type(data))\n",
    "test_data = data.iloc[:40]\n",
    "train_data = data.iloc[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58f320a-b42f-4935-beef-1a0c81e61af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]\n",
    "        sample[\"grace_value\"] = [[sample[\"grace_value\"]], [0]]\n",
    "        row = np.concatenate((sample[\"evap_value\"], sample[\"lvl1_value\"], sample[\"lvl2_value\"], sample[\"lvl3_value\"], sample[\"lvl4_value\"], sample[\"precip_value\"], sample[\"grace_value\"]), axis=1)\n",
    "        row_concat = np.concatenate((row[0], row[1])) \n",
    "        x = torch.tensor(row_concat, dtype=torch.float32)       \n",
    "        y = torch.tensor(sample['target'], dtype=torch.float32)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e362c7-5a5c-4613-9732-dedb2b9aa2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = MyDataset(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2209436-5826-4e39-8937-e0625fb23d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3c554827-e62f-43cd-b539-104ccfde3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_184/1931264250.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample[\"grace_value\"] = [[sample[\"grace_value\"]], [0]]\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class MyLSTM(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x.unsqueeze(1))\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x.squeeze()\n",
    "\n",
    "\n",
    "# konwersja danych na tensor i załadowanie do DataLoader\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    x = [item[0] for item in batch]\n",
    "    y = [item[1] for item in batch]\n",
    "    x = torch.nn.utils.rnn.pad_sequence(x, batch_first=True)\n",
    "    y = torch.stack(y)\n",
    "    return x, y\n",
    "\n",
    "def collate_fn_lstm(batch):\n",
    "    \"\"\"\n",
    "    Funkcja collate dla sekwencji wejściowych dla sieci LSTM.\n",
    "    \"\"\"\n",
    "    # Sortujemy batch względem długości sekwencji wejściowych\n",
    "    batch = sorted(batch, key=lambda x: x[0].shape[0], reverse=True)\n",
    "    \n",
    "    # Tworzymy mini-batche z wyrównaniem długości sekwencji wejściowych\n",
    "    inputs = [torch.FloatTensor(item[0]) for item in batch]\n",
    "    inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=False)\n",
    "    \n",
    "    # Tworzymy mini-batche z etykietami\n",
    "    targets = [torch.LongTensor(item[1]) for item in batch]\n",
    "    targets = torch.nn.utils.rnn.pad_sequence(targets, batch_first=False)\n",
    "    \n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "my_dataloader = DataLoader(my_dataset, batch_size=batch_size, shuffle=True) ## collate_fn=collate_fn)\n",
    "\n",
    "# inicjalizacja modelu i uruchomienie treningu\n",
    "model = MyLSTM(input_size=390, hidden_size=50, output_size=1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for batch_x, batch_y in my_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x)\n",
    "        loss = criterion(y_pred, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b6ce3514-fa32-4c51-8c8d-ac31d554ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b7906015-b20a-429b-bf81-e6c8d3e9ad8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0368\n",
      "R^2: -1.2025\n",
      "MAE: 0.1276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_184/1931264250.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample[\"grace_value\"] = [[sample[\"grace_value\"]], [0]]\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_dataloader:\n",
    "        y_true += batch_y.tolist()\n",
    "        y_pred += model(batch_x).tolist()\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"R^2: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5556a13-ede0-42c7-aa81-8b4d70c701be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
